{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2J7YQbaTwCoxrqyY4leZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukhyun-lee/stock_market_analysis/blob/main/%EC%A4%91%EA%B8%89/7%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "cnN5HRe56JpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_Q_XjG1OqEDd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine, load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = load_wine(as_frame=True)"
      ],
      "metadata": {
        "id": "iQBj6zJ70-_E"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine = data1.frame"
      ],
      "metadata": {
        "id": "zeYkNzJd1C6U"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = load_breast_cancer(as_frame=True)"
      ],
      "metadata": {
        "id": "sgF2AlzW1FqU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast = data2.frame"
      ],
      "metadata": {
        "id": "qndKBTLw1Kb7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_mjOLTl1RP7",
        "outputId": "497fc6b1-b537-4c23-9c7b-8dd7dcb11837"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178 entries, 0 to 177\n",
            "Data columns (total 14 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   alcohol                       178 non-null    float64\n",
            " 1   malic_acid                    178 non-null    float64\n",
            " 2   ash                           178 non-null    float64\n",
            " 3   alcalinity_of_ash             178 non-null    float64\n",
            " 4   magnesium                     178 non-null    float64\n",
            " 5   total_phenols                 178 non-null    float64\n",
            " 6   flavanoids                    178 non-null    float64\n",
            " 7   nonflavanoid_phenols          178 non-null    float64\n",
            " 8   proanthocyanins               178 non-null    float64\n",
            " 9   color_intensity               178 non-null    float64\n",
            " 10  hue                           178 non-null    float64\n",
            " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
            " 12  proline                       178 non-null    float64\n",
            " 13  target                        178 non-null    int64  \n",
            "dtypes: float64(13), int64(1)\n",
            "memory usage: 19.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "YOqcx2mr1xni",
        "outputId": "e6172846-b880-4a4f-dab1-7653f19c21e6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
              "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
              "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
              "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
              "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
              "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
              "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
              "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
              "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
              "\n",
              "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "count     178.000000  178.000000            178.000000       178.000000   \n",
              "mean        2.295112    2.029270              0.361854         1.590899   \n",
              "std         0.625851    0.998859              0.124453         0.572359   \n",
              "min         0.980000    0.340000              0.130000         0.410000   \n",
              "25%         1.742500    1.205000              0.270000         1.250000   \n",
              "50%         2.355000    2.135000              0.340000         1.555000   \n",
              "75%         2.800000    2.875000              0.437500         1.950000   \n",
              "max         3.880000    5.080000              0.660000         3.580000   \n",
              "\n",
              "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
              "count       178.000000  178.000000                    178.000000   178.000000   \n",
              "mean          5.058090    0.957449                      2.611685   746.893258   \n",
              "std           2.318286    0.228572                      0.709990   314.907474   \n",
              "min           1.280000    0.480000                      1.270000   278.000000   \n",
              "25%           3.220000    0.782500                      1.937500   500.500000   \n",
              "50%           4.690000    0.965000                      2.780000   673.500000   \n",
              "75%           6.200000    1.120000                      3.170000   985.000000   \n",
              "max          13.000000    1.710000                      4.000000  1680.000000   \n",
              "\n",
              "           target  \n",
              "count  178.000000  \n",
              "mean     0.938202  \n",
              "std      0.775035  \n",
              "min      0.000000  \n",
              "25%      0.000000  \n",
              "50%      1.000000  \n",
              "75%      2.000000  \n",
              "max      2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb196c16-8b43-4bd4-854d-3b37de14a0f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "      <td>0.938202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "      <td>0.775035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb196c16-8b43-4bd4-854d-3b37de14a0f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb196c16-8b43-4bd4-854d-3b37de14a0f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb196c16-8b43-4bd4-854d-3b37de14a0f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.boxplot(figsize=(20,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "a9CDzj3S108j",
        "outputId": "1d546dad-6f6b-4d85-d709-f7d32c9cc884"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "LvGfhnZZ149_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "NrIYj_sa2iDq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLFI2I732mry",
        "outputId": "97ead139-2a2e-4e5c-f8a1-96e39e081dda"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66666667, 0.66666667, 0.61111111, 0.61111111, 0.61111111,\n",
              "       0.61111111, 0.72222222, 0.66666667, 0.82352941, 0.76470588])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.proline.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRQM_kDoQDYJ",
        "outputId": "7891963f-ce65-477c-93e2-70824e99abca"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314.9074742768491"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.proline.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS1kPDSMQHEA",
        "outputId": "49f05c07-db64-4d7b-ff02-833e03902204"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "746.8932584269663"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#standard scaler"
      ],
      "metadata": {
        "id": "dqgR5TtD3Say"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine['proline'] = wine.proline.map(lambda x: (x-wine.proline.mean())/wine.proline.std())"
      ],
      "metadata": {
        "id": "6sPJeAMA23-m"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10)   #=> 편차는 크지만 성능이 올라감"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLMFPVIp3gyB",
        "outputId": "0831e58a-3ac9-4071-d444-7b491651aae5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72222222, 0.94444444, 0.72222222, 0.94444444, 0.88888889,\n",
              "       0.94444444, 0.72222222, 1.        , 0.82352941, 0.82352941])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine['proline'] = wine.proline.map(lambda x: (x-wine.proline.min()/(wine.proline.max()-x-wine.proline.min())))"
      ],
      "metadata": {
        "id": "NBRwy74i6pdt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V34OUVoP6vqN",
        "outputId": "9c9eeb95-448a-4857-dfc3-e789a347aef6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72222222, 0.94444444, 0.77777778, 0.94444444, 0.88888889,\n",
              "       0.94444444, 0.72222222, 1.        , 0.82352941, 0.82352941])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#minmax scaler"
      ],
      "metadata": {
        "id": "gXzKXYrP4dOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine, load_breast_cancer"
      ],
      "metadata": {
        "id": "LS5CFrc54jJ4"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = load_wine(as_frame=True)"
      ],
      "metadata": {
        "id": "v86wy6Wt4mSw"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine = data1.frame"
      ],
      "metadata": {
        "id": "e2XtUERE4nHH"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.proline.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9s7GNFO4p13",
        "outputId": "29f75542-f2cc-469e-83d6-0ea8ee21d87b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1680.0"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.proline.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhLf4If34trO",
        "outputId": "5bbd6c3d-c869-409d-a1f7-00205de38099"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278.0"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine['proline'] = wine.proline.map(lambda x: (x-wine.proline.min()/(wine.proline.max()-x-wine.proline.min())))"
      ],
      "metadata": {
        "id": "0-JOSDmi4w1P"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YupKwJA5Jne",
        "outputId": "1d437e3c-bc1e-4df5-b4a6-af2ec7daf3dd"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66666667, 0.66666667, 0.61111111, 0.61111111, 0.61111111,\n",
              "       0.61111111, 0.72222222, 0.66666667, 0.82352941, 0.76470588])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#minmax + standardscaler =>동시에 사용할 때 뒤 영향 단, 항상 똑같이 값 나오지 않음"
      ],
      "metadata": {
        "id": "y-EdaHSm5RXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine['proline'] = wine.proline.map(lambda x: (x-wine.proline.mean())/wine.proline.std())"
      ],
      "metadata": {
        "id": "Hq85vr9l5cYO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsX7wV9R5gYt",
        "outputId": "a84c65c9-0e16-4654-b8b3-3bcdc94002af"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72222222, 0.94444444, 0.72222222, 0.94444444, 0.88888889,\n",
              "       0.94444444, 0.72222222, 1.        , 0.82352941, 0.82352941])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler  #=> 아주 중요  데이터표현 공간을 변환시킴"
      ],
      "metadata": {
        "id": "FzwdaH5_B8f2"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm = MinMaxScaler()"
      ],
      "metadata": {
        "id": "bhumnKCzB8dr"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm.fit_transform(wine[['proline']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umvGHzlGB8bR",
        "outputId": "6d671c7b-5d0b-46b2-aac3-64d7a0f58b8b"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.56043036],\n",
              "       [0.54976592],\n",
              "       [0.6456212 ],\n",
              "       [0.85930071],\n",
              "       [0.3255524 ],\n",
              "       [0.83950917],\n",
              "       [0.71959174],\n",
              "       [0.72307225],\n",
              "       [0.54621064],\n",
              "       [0.54621064],\n",
              "       [0.87997417],\n",
              "       [0.7126104 ],\n",
              "       [0.74032358],\n",
              "       [0.62080585],\n",
              "       [0.9058735 ],\n",
              "       [0.73345986],\n",
              "       [0.7126104 ],\n",
              "       [0.606611  ],\n",
              "       [1.        ],\n",
              "       [0.40388335],\n",
              "       [0.35759939],\n",
              "       [0.3504781 ],\n",
              "       [0.53909943],\n",
              "       [0.52487467],\n",
              "       [0.40388335],\n",
              "       [0.39320318],\n",
              "       [0.65270342],\n",
              "       [0.71610417],\n",
              "       [0.45371652],\n",
              "       [0.53909943],\n",
              "       [0.71610417],\n",
              "       [0.88345617],\n",
              "       [0.50708992],\n",
              "       [0.6809795 ],\n",
              "       [0.58175189],\n",
              "       [0.45727546],\n",
              "       [0.42880165],\n",
              "       [0.58885649],\n",
              "       [0.52843114],\n",
              "       [0.34335665],\n",
              "       [0.36828101],\n",
              "       [0.53909943],\n",
              "       [0.58175189],\n",
              "       [0.28638023],\n",
              "       [0.43236114],\n",
              "       [0.57109246],\n",
              "       [0.56043036],\n",
              "       [0.50353252],\n",
              "       [0.55687579],\n",
              "       [0.69858646],\n",
              "       [0.62080585],\n",
              "       [0.70209871],\n",
              "       [0.64916283],\n",
              "       [0.7745969 ],\n",
              "       [0.55687579],\n",
              "       [0.5995105 ],\n",
              "       [0.49285952],\n",
              "       [0.70560709],\n",
              "       [0.71610417],\n",
              "       [0.17240876],\n",
              "       [0.28638023],\n",
              "       [0.12254099],\n",
              "       [0.25076636],\n",
              "       [0.10116836],\n",
              "       [0.05485976],\n",
              "       [0.28495572],\n",
              "       [0.15958587],\n",
              "       [0.16528495],\n",
              "       [0.33623506],\n",
              "       [0.31344503],\n",
              "       [0.42168245],\n",
              "       [0.09404407],\n",
              "       [0.13821399],\n",
              "       [0.50353252],\n",
              "       [0.43307303],\n",
              "       [0.10686777],\n",
              "       [0.08122024],\n",
              "       [0.15816109],\n",
              "       [0.33623506],\n",
              "       [0.13180233],\n",
              "       [0.        ],\n",
              "       [0.31059618],\n",
              "       [0.25076636],\n",
              "       [0.16884687],\n",
              "       [0.17240876],\n",
              "       [0.12254099],\n",
              "       [0.15459914],\n",
              "       [0.20232811],\n",
              "       [0.28638023],\n",
              "       [0.24720485],\n",
              "       [0.1439132 ],\n",
              "       [0.12254099],\n",
              "       [0.15459914],\n",
              "       [0.00854969],\n",
              "       [0.04773522],\n",
              "       [0.46937519],\n",
              "       [0.24720485],\n",
              "       [0.10686777],\n",
              "       [0.27213497],\n",
              "       [0.09119434],\n",
              "       [0.30774731],\n",
              "       [0.20232811],\n",
              "       [0.11399199],\n",
              "       [0.09760622],\n",
              "       [0.28068217],\n",
              "       [0.02636141],\n",
              "       [0.16528495],\n",
              "       [0.14961238],\n",
              "       [0.02422402],\n",
              "       [0.28638023],\n",
              "       [0.20232811],\n",
              "       [0.03348605],\n",
              "       [0.23438323],\n",
              "       [0.1111423 ],\n",
              "       [0.07623316],\n",
              "       [0.09190677],\n",
              "       [0.15459914],\n",
              "       [0.04773522],\n",
              "       [0.06697139],\n",
              "       [0.20375281],\n",
              "       [0.24720485],\n",
              "       [0.13322715],\n",
              "       [0.06198426],\n",
              "       [0.07267095],\n",
              "       [0.07267095],\n",
              "       [0.07124606],\n",
              "       [0.0527224 ],\n",
              "       [0.13393955],\n",
              "       [0.04559785],\n",
              "       [0.21515033],\n",
              "       [0.25076636],\n",
              "       [0.17953252],\n",
              "       [0.2009034 ],\n",
              "       [0.22939698],\n",
              "       [0.26501219],\n",
              "       [0.2970639 ],\n",
              "       [0.31486944],\n",
              "       [0.16884687],\n",
              "       [0.21515033],\n",
              "       [0.22227369],\n",
              "       [0.22939698],\n",
              "       [0.35759939],\n",
              "       [0.17240876],\n",
              "       [0.19377984],\n",
              "       [0.41100317],\n",
              "       [0.39320318],\n",
              "       [0.09760622],\n",
              "       [0.24720485],\n",
              "       [0.26501219],\n",
              "       [0.19377984],\n",
              "       [0.15816109],\n",
              "       [0.1439132 ],\n",
              "       [0.10473049],\n",
              "       [0.28281895],\n",
              "       [0.25788932],\n",
              "       [0.31843046],\n",
              "       [0.1439132 ],\n",
              "       [0.42880165],\n",
              "       [0.27213497],\n",
              "       [0.24364332],\n",
              "       [0.17240876],\n",
              "       [0.28638023],\n",
              "       [0.2080269 ],\n",
              "       [0.28281895],\n",
              "       [0.24008176],\n",
              "       [0.17240876],\n",
              "       [0.2970639 ],\n",
              "       [0.28994148],\n",
              "       [0.33623506],\n",
              "       [0.25076636],\n",
              "       [0.16528495],\n",
              "       [0.13678918],\n",
              "       [0.27213497],\n",
              "       [0.32911332],\n",
              "       [0.33623506],\n",
              "       [0.39676329],\n",
              "       [0.40032335],\n",
              "       [0.2009034 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = StandardScaler()"
      ],
      "metadata": {
        "id": "WoW5p8qfB8Yu"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.fit_transform(wine[['proline']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atSoxYcbpn4w",
        "outputId": "6f403918-7748-40a7-a914-dabac320abb5"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.01277149],\n",
              "       [ 0.96508295],\n",
              "       [ 1.3937223 ],\n",
              "       [ 2.34924033],\n",
              "       [-0.03754034],\n",
              "       [ 2.26073779],\n",
              "       [ 1.72449891],\n",
              "       [ 1.74006281],\n",
              "       [ 0.94918467],\n",
              "       [ 0.94918467],\n",
              "       [ 2.44168653],\n",
              "       [ 1.69328021],\n",
              "       [ 1.81720619],\n",
              "       [ 1.28275466],\n",
              "       [ 2.55750146],\n",
              "       [ 1.78651346],\n",
              "       [ 1.69328021],\n",
              "       [ 1.21927907],\n",
              "       [ 2.97841016],\n",
              "       [ 0.31273484],\n",
              "       [ 0.10576526],\n",
              "       [ 0.07392076],\n",
              "       [ 0.91738525],\n",
              "       [ 0.85377591],\n",
              "       [ 0.31273484],\n",
              "       [ 0.26497598],\n",
              "       [ 1.42539212],\n",
              "       [ 1.70890341],\n",
              "       [ 0.53557553],\n",
              "       [ 0.91738525],\n",
              "       [ 1.70890341],\n",
              "       [ 2.45725709],\n",
              "       [ 0.77424721],\n",
              "       [ 1.55183521],\n",
              "       [ 1.10811573],\n",
              "       [ 0.55149018],\n",
              "       [ 0.42416285],\n",
              "       [ 1.13988562],\n",
              "       [ 0.86967947],\n",
              "       [ 0.04207555],\n",
              "       [ 0.15353063],\n",
              "       [ 0.91738525],\n",
              "       [ 1.10811573],\n",
              "       [-0.2127079 ],\n",
              "       [ 0.44007996],\n",
              "       [ 1.0604496 ],\n",
              "       [ 1.01277149],\n",
              "       [ 0.75833947],\n",
              "       [ 0.9968764 ],\n",
              "       [ 1.63056887],\n",
              "       [ 1.28275466],\n",
              "       [ 1.6462747 ],\n",
              "       [ 1.40955954],\n",
              "       [ 1.97046738],\n",
              "       [ 0.9968764 ],\n",
              "       [ 1.18752752],\n",
              "       [ 0.71061267],\n",
              "       [ 1.66196328],\n",
              "       [ 1.70890341],\n",
              "       [-0.72235801],\n",
              "       [-0.2127079 ],\n",
              "       [-0.94535346],\n",
              "       [-0.37196365],\n",
              "       [-1.04092616],\n",
              "       [-1.24800593],\n",
              "       [-0.21907792],\n",
              "       [-0.7796986 ],\n",
              "       [-0.75421379],\n",
              "       [ 0.01022967],\n",
              "       [-0.0916813 ],\n",
              "       [ 0.39232771],\n",
              "       [-1.07278411],\n",
              "       [-0.87526797],\n",
              "       [ 0.75833947],\n",
              "       [ 0.44326334],\n",
              "       [-1.01543993],\n",
              "       [-1.13012887],\n",
              "       [-0.78606982],\n",
              "       [ 0.01022967],\n",
              "       [-0.90393918],\n",
              "       [-1.4933242 ],\n",
              "       [-0.10442059],\n",
              "       [-0.37196365],\n",
              "       [-0.73828587],\n",
              "       [-0.72235801],\n",
              "       [-0.94535346],\n",
              "       [-0.80199793],\n",
              "       [-0.58856665],\n",
              "       [-0.2127079 ],\n",
              "       [-0.38788979],\n",
              "       [-0.84978261],\n",
              "       [-0.94535346],\n",
              "       [-0.80199793],\n",
              "       [-1.45509226],\n",
              "       [-1.27986497],\n",
              "       [ 0.60559696],\n",
              "       [-0.38788979],\n",
              "       [-1.01543993],\n",
              "       [-0.27640891],\n",
              "       [-1.08552734],\n",
              "       [-0.11715996],\n",
              "       [-0.58856665],\n",
              "       [-0.98358232],\n",
              "       [-1.05685511],\n",
              "       [-0.23818809],\n",
              "       [-1.37544297],\n",
              "       [-0.75421379],\n",
              "       [-0.82429738],\n",
              "       [-1.38500084],\n",
              "       [-0.2127079 ],\n",
              "       [-0.58856665],\n",
              "       [-1.34358349],\n",
              "       [-0.44522465],\n",
              "       [-0.99632534],\n",
              "       [-1.15242976],\n",
              "       [-1.08234153],\n",
              "       [-0.80199793],\n",
              "       [-1.27986497],\n",
              "       [-1.19384592],\n",
              "       [-0.58219575],\n",
              "       [-0.38788979],\n",
              "       [-0.89756779],\n",
              "       [-1.21614705],\n",
              "       [-1.16835902],\n",
              "       [-1.16835902],\n",
              "       [-1.17473074],\n",
              "       [-1.25756363],\n",
              "       [-0.89438209],\n",
              "       [-1.28942271],\n",
              "       [-0.53122906],\n",
              "       [-0.37196365],\n",
              "       [-0.69050248],\n",
              "       [-0.59493755],\n",
              "       [-0.46752185],\n",
              "       [-0.30826008],\n",
              "       [-0.16493337],\n",
              "       [-0.08531169],\n",
              "       [-0.73828587],\n",
              "       [-0.53122906],\n",
              "       [-0.49937529],\n",
              "       [-0.46752185],\n",
              "       [ 0.10576526],\n",
              "       [-0.72235801],\n",
              "       [-0.62679224],\n",
              "       [ 0.3445728 ],\n",
              "       [ 0.26497598],\n",
              "       [-1.05685511],\n",
              "       [-0.38788979],\n",
              "       [-0.30826008],\n",
              "       [-0.62679224],\n",
              "       [-0.78606982],\n",
              "       [-0.84978261],\n",
              "       [-1.02499725],\n",
              "       [-0.22863298],\n",
              "       [-0.34011166],\n",
              "       [-0.06938776],\n",
              "       [-0.84978261],\n",
              "       [ 0.42416285],\n",
              "       [-0.27640891],\n",
              "       [-0.40381602],\n",
              "       [-0.72235801],\n",
              "       [-0.2127079 ],\n",
              "       [-0.56308315],\n",
              "       [-0.22863298],\n",
              "       [-0.41974234],\n",
              "       [-0.72235801],\n",
              "       [-0.16493337],\n",
              "       [-0.19678294],\n",
              "       [ 0.01022967],\n",
              "       [-0.37196365],\n",
              "       [-0.75421379],\n",
              "       [-0.88163934],\n",
              "       [-0.27640891],\n",
              "       [-0.02161685],\n",
              "       [ 0.01022967],\n",
              "       [ 0.28089585],\n",
              "       [ 0.29681547],\n",
              "       [-0.59493755]])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ro = RobustScaler()   #=>   아웃라이어 있을 경우"
      ],
      "metadata": {
        "id": "694T15gwpqsX"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ro.fit_transform(wine[['proline']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzPinLjIpu9P",
        "outputId": "52a9a76a-99bc-4c47-f0b2-f0c7a6266924"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.80773186],\n",
              "       [ 0.7768218 ],\n",
              "       [ 1.05465093],\n",
              "       [ 1.67398449],\n",
              "       [ 0.12695625],\n",
              "       [ 1.61662022],\n",
              "       [ 1.26904882],\n",
              "       [ 1.2791368 ],\n",
              "       [ 0.7665171 ],\n",
              "       [ 0.7665171 ],\n",
              "       [ 1.7339049 ],\n",
              "       [ 1.24881395],\n",
              "       [ 1.32913846],\n",
              "       [ 0.98272556],\n",
              "       [ 1.80897211],\n",
              "       [ 1.3092445 ],\n",
              "       [ 1.24881395],\n",
              "       [ 0.94158289],\n",
              "       [ 2.0817905 ],\n",
              "       [ 0.35399244],\n",
              "       [ 0.21984196],\n",
              "       [ 0.19920146],\n",
              "       [ 0.74590581],\n",
              "       [ 0.70467645],\n",
              "       [ 0.35399244],\n",
              "       [ 0.32303681],\n",
              "       [ 1.0751782 ],\n",
              "       [ 1.25894037],\n",
              "       [ 0.49843003],\n",
              "       [ 0.74590581],\n",
              "       [ 1.25894037],\n",
              "       [ 1.7439972 ],\n",
              "       [ 0.65312871],\n",
              "       [ 1.15713422],\n",
              "       [ 0.86953068],\n",
              "       [ 0.50874535],\n",
              "       [ 0.4262162 ],\n",
              "       [ 0.89012282],\n",
              "       [ 0.71498459],\n",
              "       [ 0.1785605 ],\n",
              "       [ 0.25080181],\n",
              "       [ 0.74590581],\n",
              "       [ 0.86953068],\n",
              "       [ 0.01341873],\n",
              "       [ 0.43653312],\n",
              "       [ 0.83863515],\n",
              "       [ 0.80773186],\n",
              "       [ 0.64281787],\n",
              "       [ 0.79742921],\n",
              "       [ 1.20816664],\n",
              "       [ 0.98272556],\n",
              "       [ 1.21834661],\n",
              "       [ 1.06491607],\n",
              "       [ 1.42847703],\n",
              "       [ 0.79742921],\n",
              "       [ 0.92100264],\n",
              "       [ 0.61188302],\n",
              "       [ 1.2285154 ],\n",
              "       [ 1.25894037],\n",
              "       [-0.31691875],\n",
              "       [ 0.01341873],\n",
              "       [-0.46145665],\n",
              "       [-0.08980531],\n",
              "       [-0.52340355],\n",
              "       [-0.65762546],\n",
              "       [ 0.0092899 ],\n",
              "       [-0.35408493],\n",
              "       [-0.33756656],\n",
              "       [ 0.15791911],\n",
              "       [ 0.09186396],\n",
              "       [ 0.40558177],\n",
              "       [-0.54405276],\n",
              "       [-0.41602967],\n",
              "       [ 0.64281787],\n",
              "       [ 0.43859648],\n",
              "       [-0.50688426],\n",
              "       [-0.58122164],\n",
              "       [-0.35821453],\n",
              "       [ 0.15791911],\n",
              "       [-0.43461335],\n",
              "       [-0.81663223],\n",
              "       [ 0.0836068 ],\n",
              "       [-0.08980531],\n",
              "       [-0.32724263],\n",
              "       [-0.31691875],\n",
              "       [-0.46145665],\n",
              "       [-0.36853858],\n",
              "       [-0.23019984],\n",
              "       [ 0.01341873],\n",
              "       [-0.10012808],\n",
              "       [-0.39951094],\n",
              "       [-0.46145665],\n",
              "       [-0.36853858],\n",
              "       [-0.79185161],\n",
              "       [-0.67827538],\n",
              "       [ 0.54381549],\n",
              "       [-0.10012808],\n",
              "       [-0.50688426],\n",
              "       [-0.02787005],\n",
              "       [-0.55231248],\n",
              "       [ 0.07534958],\n",
              "       [-0.23019984],\n",
              "       [-0.48623527],\n",
              "       [-0.53372814],\n",
              "       [-0.00309664],\n",
              "       [-0.74022571],\n",
              "       [-0.33756656],\n",
              "       [-0.38299231],\n",
              "       [-0.74642079],\n",
              "       [ 0.01341873],\n",
              "       [-0.23019984],\n",
              "       [-0.71957551],\n",
              "       [-0.13729054],\n",
              "       [-0.49449485],\n",
              "       [-0.59567631],\n",
              "       [-0.55024755],\n",
              "       [-0.36853858],\n",
              "       [-0.67827538],\n",
              "       [-0.62252082],\n",
              "       [-0.22607045],\n",
              "       [-0.10012808],\n",
              "       [-0.43048364],\n",
              "       [-0.63697564],\n",
              "       [-0.6060011 ],\n",
              "       [-0.6060011 ],\n",
              "       [-0.61013102],\n",
              "       [-0.66382042],\n",
              "       [-0.42841878],\n",
              "       [-0.68447037],\n",
              "       [-0.19303561],\n",
              "       [-0.08980531],\n",
              "       [-0.29627111],\n",
              "       [-0.23432924],\n",
              "       [-0.15174282],\n",
              "       [-0.04851487],\n",
              "       [ 0.04438452],\n",
              "       [ 0.09599252],\n",
              "       [-0.32724263],\n",
              "       [-0.19303561],\n",
              "       [-0.17238911],\n",
              "       [-0.15174282],\n",
              "       [ 0.21984196],\n",
              "       [-0.31691875],\n",
              "       [-0.25497635],\n",
              "       [ 0.3746287 ],\n",
              "       [ 0.32303681],\n",
              "       [-0.53372814],\n",
              "       [-0.10012808],\n",
              "       [-0.04851487],\n",
              "       [-0.25497635],\n",
              "       [-0.35821453],\n",
              "       [-0.39951094],\n",
              "       [-0.51307899],\n",
              "       [ 0.00309664],\n",
              "       [-0.06915996],\n",
              "       [ 0.10631386],\n",
              "       [-0.39951094],\n",
              "       [ 0.4262162 ],\n",
              "       [-0.02787005],\n",
              "       [-0.11045091],\n",
              "       [-0.31691875],\n",
              "       [ 0.01341873],\n",
              "       [-0.21368233],\n",
              "       [ 0.00309664],\n",
              "       [-0.1207738 ],\n",
              "       [-0.31691875],\n",
              "       [ 0.04438452],\n",
              "       [ 0.02374074],\n",
              "       [ 0.15791911],\n",
              "       [-0.08980531],\n",
              "       [-0.33756656],\n",
              "       [-0.42015937],\n",
              "       [-0.02787005],\n",
              "       [ 0.1372773 ],\n",
              "       [ 0.15791911],\n",
              "       [ 0.33335551],\n",
              "       [ 0.34367406],\n",
              "       [-0.23432924]])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpzE3bc6py2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter, Wrapper, Embeded"
      ],
      "metadata": {
        "id": "e_QTsbg5B66e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "11dfb1QBCCKe"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "vzW7CqDgCMtV"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.fit(wine.iloc[:,:-1], wine.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "fAzRZkUJCQbe",
        "outputId": "64a4a950-45fc-4dad-8552-0c201e5a7c2c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree"
      ],
      "metadata": {
        "id": "aOHIToM2CaA-"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(dc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "JtZRK6tKCgFt",
        "outputId": "06599471-145d-44c6-d24f-52199acd49a7"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5657894736842105, 0.9166666666666666, 'x[12] <= 754.57\\ngini = 0.658\\nsamples = 178\\nvalue = [59, 71, 48]'),\n",
              " Text(0.34210526315789475, 0.75, 'x[11] <= 2.115\\ngini = 0.492\\nsamples = 111\\nvalue = [2, 67, 42]'),\n",
              " Text(0.21052631578947367, 0.5833333333333334, 'x[10] <= 0.935\\ngini = 0.227\\nsamples = 46\\nvalue = [0, 6, 40]'),\n",
              " Text(0.10526315789473684, 0.4166666666666667, 'x[6] <= 1.58\\ngini = 0.049\\nsamples = 40\\nvalue = [0, 1, 39]'),\n",
              " Text(0.05263157894736842, 0.25, 'gini = 0.0\\nsamples = 39\\nvalue = [0, 0, 39]'),\n",
              " Text(0.15789473684210525, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
              " Text(0.3157894736842105, 0.4166666666666667, 'x[2] <= 2.45\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 5, 1]'),\n",
              " Text(0.2631578947368421, 0.25, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
              " Text(0.3684210526315789, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(0.47368421052631576, 0.5833333333333334, 'x[6] <= 0.795\\ngini = 0.117\\nsamples = 65\\nvalue = [2, 61, 2]'),\n",
              " Text(0.42105263157894735, 0.4166666666666667, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
              " Text(0.5263157894736842, 0.4166666666666667, 'x[0] <= 13.175\\ngini = 0.061\\nsamples = 63\\nvalue = [2, 61, 0]'),\n",
              " Text(0.47368421052631576, 0.25, 'gini = 0.0\\nsamples = 58\\nvalue = [0, 58, 0]'),\n",
              " Text(0.5789473684210527, 0.25, 'x[1] <= 2.125\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3, 0]'),\n",
              " Text(0.5263157894736842, 0.08333333333333333, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
              " Text(0.631578947368421, 0.08333333333333333, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
              " Text(0.7894736842105263, 0.75, 'x[6] <= 2.165\\ngini = 0.265\\nsamples = 67\\nvalue = [57, 4, 6]'),\n",
              " Text(0.6842105263157895, 0.5833333333333334, 'x[10] <= 0.803\\ngini = 0.375\\nsamples = 8\\nvalue = [0, 2, 6]'),\n",
              " Text(0.631578947368421, 0.4166666666666667, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
              " Text(0.7368421052631579, 0.4166666666666667, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
              " Text(0.8947368421052632, 0.5833333333333334, 'x[4] <= 135.5\\ngini = 0.065\\nsamples = 59\\nvalue = [57, 2, 0]'),\n",
              " Text(0.8421052631578947, 0.4166666666666667, 'gini = 0.0\\nsamples = 57\\nvalue = [57, 0, 0]'),\n",
              " Text(0.9473684210526315, 0.4166666666666667, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKEJzkWWEZGE",
        "outputId": "95f338b0-de7b-4b83-fffb-123ad39ccbc2"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "       'proanthocyanins', 'color_intensity', 'hue',\n",
              "       'od280/od315_of_diluted_wines', 'proline', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dc.feature_importances_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep_YvqDRC_BF",
        "outputId": "be36c140-b6c1-4098-f043-16d0943eaca7"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01257056, 0.02048135, 0.01422316, 0.        , 0.03297845,\n",
              "       0.        , 0.14144668, 0.        , 0.        , 0.        ,\n",
              "       0.08378678, 0.31204257, 0.38247045])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "알고리즘 자체 feature를 선택할수 있다면 => 임베디드 방식"
      ],
      "metadata": {
        "id": "DT2q2WC0DMaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "ADsZ7866DHak"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(DecisionTreeClassifier(), wine.iloc[:,:-1], wine.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT9D4MoEq5ZF",
        "outputId": "c3d8eba8-1d8e-4024-b25e-6a9841c90892"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83333333, 0.88888889, 0.72222222, 0.88888889, 0.83333333,\n",
              "       0.83333333, 1.        , 0.94444444, 0.94117647, 0.76470588])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(DecisionTreeClassifier(), wine.iloc[:,:-1], wine.target, cv=10).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXxA_Yj_EF8M",
        "outputId": "0c18f5f8-ae51-4d80-d397-ac16060d05e1"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.865032679738562"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine2 = wine[['proline','od280/od315_of_diluted_wines','flavanoids','hue','target']]"
      ],
      "metadata": {
        "id": "v6lOSLNoEQic"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B2N4SoPFEkR0",
        "outputId": "56877ee5-651c-46d4-a65d-d523d96da72c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         proline  od280/od315_of_diluted_wines  flavanoids   hue  target\n",
              "0    1064.175074                          3.92        3.06  1.04       0\n",
              "1    1049.210227                          3.40        2.76  1.05       0\n",
              "2    1183.718894                          3.17        3.24  1.03       0\n",
              "3    1483.564103                          3.45        3.49  0.86       0\n",
              "4     734.583208                          2.93        2.69  1.04       0\n",
              "..           ...                           ...         ...   ...     ...\n",
              "173   739.580060                          1.74        0.61  0.64       2\n",
              "174   749.573620                          1.56        0.75  0.70       2\n",
              "175   834.509700                          1.56        0.69  0.59       2\n",
              "176   839.505338                          1.62        0.68  0.60       2\n",
              "177   559.669834                          1.60        0.76  0.61       2\n",
              "\n",
              "[178 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e70a38e2-dc84-418d-b9cb-0156a707da00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proline</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>hue</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1064.175074</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.06</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049.210227</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.76</td>\n",
              "      <td>1.05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1183.718894</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.24</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1483.564103</td>\n",
              "      <td>3.45</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>734.583208</td>\n",
              "      <td>2.93</td>\n",
              "      <td>2.69</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>739.580060</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.64</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>749.573620</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.70</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>834.509700</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.59</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>839.505338</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.60</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>559.669834</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.61</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e70a38e2-dc84-418d-b9cb-0156a707da00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e70a38e2-dc84-418d-b9cb-0156a707da00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e70a38e2-dc84-418d-b9cb-0156a707da00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(DecisionTreeClassifier(), wine2.iloc[:,:-1], wine2.target, cv=10).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF8BwZtdEmtI",
        "outputId": "51aaea3a-e2c8-4267-edc1-b73cd553de85"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9163398692810457"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "==> overfitting이 줄어듬 (즉. 성능이 좋아짐) 평균값은 높힐수도 낮아질수도 있음"
      ],
      "metadata": {
        "id": "D1xl8MRCFRoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filter"
      ],
      "metadata": {
        "id": "9vpRcbHGGEX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2"
      ],
      "metadata": {
        "id": "eJsS6MFIFnuq"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2    #=>카이제곱"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPklNgclFxAD",
        "outputId": "0f9289fe-6468-469d-b7b2-b797450dc737"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function sklearn.feature_selection._univariate_selection.chi2(X, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssb = SelectKBest(chi2, k=5)   #=>  카이제곱 점수 매겨 5개 골라"
      ],
      "metadata": {
        "id": "dYWbpQuJGIg7"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssb.fit_transform(wine.iloc[:,:-1], wine.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL7nibGVGOb7",
        "outputId": "2e8971db-4b76-4f49-c6ec-5d890249d6e2"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.56000000e+01, 1.27000000e+02, 3.06000000e+00, 5.64000000e+00,\n",
              "        1.06417507e+03],\n",
              "       [1.12000000e+01, 1.00000000e+02, 2.76000000e+00, 4.38000000e+00,\n",
              "        1.04921023e+03],\n",
              "       [1.86000000e+01, 1.01000000e+02, 3.24000000e+00, 5.68000000e+00,\n",
              "        1.18371889e+03],\n",
              "       [1.68000000e+01, 1.13000000e+02, 3.49000000e+00, 7.80000000e+00,\n",
              "        1.48356410e+03],\n",
              "       [2.10000000e+01, 1.18000000e+02, 2.69000000e+00, 4.32000000e+00,\n",
              "        7.34583208e+02],\n",
              "       [1.52000000e+01, 1.12000000e+02, 3.39000000e+00, 6.75000000e+00,\n",
              "        1.45579167e+03],\n",
              "       [1.46000000e+01, 9.60000000e+01, 2.52000000e+00, 5.25000000e+00,\n",
              "        1.28751786e+03],\n",
              "       [1.76000000e+01, 1.21000000e+02, 2.51000000e+00, 5.05000000e+00,\n",
              "        1.29240187e+03],\n",
              "       [1.40000000e+01, 9.70000000e+01, 2.98000000e+00, 5.20000000e+00,\n",
              "        1.04422129e+03],\n",
              "       [1.60000000e+01, 9.80000000e+01, 3.15000000e+00, 7.22000000e+00,\n",
              "        1.04422129e+03],\n",
              "       [1.80000000e+01, 1.05000000e+02, 3.32000000e+00, 5.75000000e+00,\n",
              "        1.51257407e+03],\n",
              "       [1.68000000e+01, 9.50000000e+01, 2.43000000e+00, 5.00000000e+00,\n",
              "        1.27772131e+03],\n",
              "       [1.60000000e+01, 8.90000000e+01, 2.76000000e+00, 5.60000000e+00,\n",
              "        1.31660976e+03],\n",
              "       [1.14000000e+01, 9.10000000e+01, 3.69000000e+00, 5.40000000e+00,\n",
              "        1.14889683e+03],\n",
              "       [1.20000000e+01, 1.02000000e+02, 3.64000000e+00, 7.50000000e+00,\n",
              "        1.54891724e+03],\n",
              "       [1.72000000e+01, 1.12000000e+02, 2.91000000e+00, 7.30000000e+00,\n",
              "        1.30697826e+03],\n",
              "       [2.00000000e+01, 1.20000000e+02, 3.14000000e+00, 6.20000000e+00,\n",
              "        1.27772131e+03],\n",
              "       [2.00000000e+01, 1.15000000e+02, 3.40000000e+00, 6.60000000e+00,\n",
              "        1.12897794e+03],\n",
              "       [1.65000000e+01, 1.08000000e+02, 3.93000000e+00, 8.70000000e+00,\n",
              "        1.68100000e+03],\n",
              "       [1.52000000e+01, 1.16000000e+02, 3.03000000e+00, 5.10000000e+00,\n",
              "        8.44500898e+02],\n",
              "       [1.60000000e+01, 1.26000000e+02, 3.17000000e+00, 5.65000000e+00,\n",
              "        7.79553055e+02],\n",
              "       [1.86000000e+01, 1.02000000e+02, 2.41000000e+00, 4.50000000e+00,\n",
              "        7.69560127e+02],\n",
              "       [1.66000000e+01, 1.01000000e+02, 2.88000000e+00, 3.80000000e+00,\n",
              "        1.03424251e+03],\n",
              "       [1.78000000e+01, 9.50000000e+01, 2.37000000e+00, 3.93000000e+00,\n",
              "        1.01428165e+03],\n",
              "       [2.00000000e+01, 9.60000000e+01, 2.61000000e+00, 3.52000000e+00,\n",
              "        8.44500898e+02],\n",
              "       [2.50000000e+01, 1.24000000e+02, 2.68000000e+00, 3.58000000e+00,\n",
              "        8.29513986e+02],\n",
              "       [1.61000000e+01, 9.30000000e+01, 2.94000000e+00, 4.80000000e+00,\n",
              "        1.19365700e+03],\n",
              "       [1.70000000e+01, 9.40000000e+01, 2.19000000e+00, 3.95000000e+00,\n",
              "        1.28262393e+03],\n",
              "       [1.94000000e+01, 1.07000000e+02, 2.97000000e+00, 4.50000000e+00,\n",
              "        9.14429158e+02],\n",
              "       [1.60000000e+01, 9.60000000e+01, 2.33000000e+00, 4.70000000e+00,\n",
              "        1.03424251e+03],\n",
              "       [2.25000000e+01, 1.01000000e+02, 3.25000000e+00, 5.70000000e+00,\n",
              "        1.28262393e+03],\n",
              "       [1.91000000e+01, 1.06000000e+02, 3.19000000e+00, 6.90000000e+00,\n",
              "        1.51746018e+03],\n",
              "       [1.72000000e+01, 1.04000000e+02, 2.69000000e+00, 3.84000000e+00,\n",
              "        9.89325243e+02],\n",
              "       [1.95000000e+01, 1.32000000e+02, 2.74000000e+00, 5.40000000e+00,\n",
              "        1.23333533e+03],\n",
              "       [1.90000000e+01, 1.10000000e+02, 2.53000000e+00, 4.20000000e+00,\n",
              "        1.09409446e+03],\n",
              "       [2.05000000e+01, 1.00000000e+02, 2.98000000e+00, 5.10000000e+00,\n",
              "        9.19423237e+02],\n",
              "       [1.55000000e+01, 1.10000000e+02, 2.68000000e+00, 4.60000000e+00,\n",
              "        8.79467433e+02],\n",
              "       [1.80000000e+01, 9.80000000e+01, 2.43000000e+00, 4.25000000e+00,\n",
              "        1.10406397e+03],\n",
              "       [1.55000000e+01, 9.80000000e+01, 2.64000000e+00, 3.70000000e+00,\n",
              "        1.01927225e+03],\n",
              "       [1.32000000e+01, 1.28000000e+02, 3.04000000e+00, 5.10000000e+00,\n",
              "        7.59566978e+02],\n",
              "       [1.62000000e+01, 1.17000000e+02, 3.29000000e+00, 6.13000000e+00,\n",
              "        7.94542010e+02],\n",
              "       [1.88000000e+01, 9.00000000e+01, 2.68000000e+00, 4.28000000e+00,\n",
              "        1.03424251e+03],\n",
              "       [1.50000000e+01, 1.01000000e+02, 3.56000000e+00, 5.43000000e+00,\n",
              "        1.09409446e+03],\n",
              "       [1.75000000e+01, 1.03000000e+02, 2.63000000e+00, 4.36000000e+00,\n",
              "        6.79614958e+02],\n",
              "       [1.70000000e+01, 1.07000000e+02, 3.00000000e+00, 5.04000000e+00,\n",
              "        8.84462282e+02],\n",
              "       [1.89000000e+01, 1.11000000e+02, 2.65000000e+00, 5.24000000e+00,\n",
              "        1.07913665e+03],\n",
              "       [1.60000000e+01, 1.02000000e+02, 3.17000000e+00, 4.90000000e+00,\n",
              "        1.06417507e+03],\n",
              "       [1.60000000e+01, 1.01000000e+02, 3.39000000e+00, 6.10000000e+00,\n",
              "        9.84333333e+02],\n",
              "       [1.88000000e+01, 1.03000000e+02, 2.92000000e+00, 6.20000000e+00,\n",
              "        1.05918713e+03],\n",
              "       [1.74000000e+01, 1.08000000e+02, 3.54000000e+00, 8.90000000e+00,\n",
              "        1.25804225e+03],\n",
              "       [1.24000000e+01, 9.20000000e+01, 3.27000000e+00, 7.20000000e+00,\n",
              "        1.14889683e+03],\n",
              "       [1.72000000e+01, 9.40000000e+01, 2.99000000e+00, 5.60000000e+00,\n",
              "        1.26297080e+03],\n",
              "       [1.40000000e+01, 1.11000000e+02, 3.74000000e+00, 7.05000000e+00,\n",
              "        1.18868868e+03],\n",
              "       [1.71000000e+01, 1.15000000e+02, 2.79000000e+00, 6.30000000e+00,\n",
              "        1.36470370e+03],\n",
              "       [1.64000000e+01, 1.18000000e+02, 2.90000000e+00, 5.85000000e+00,\n",
              "        1.05918713e+03],\n",
              "       [2.05000000e+01, 1.16000000e+02, 2.78000000e+00, 6.25000000e+00,\n",
              "        1.11901418e+03],\n",
              "       [1.63000000e+01, 1.18000000e+02, 3.00000000e+00, 6.38000000e+00,\n",
              "        9.69356481e+02],\n",
              "       [1.68000000e+01, 1.02000000e+02, 3.23000000e+00, 6.00000000e+00,\n",
              "        1.26789394e+03],\n",
              "       [1.67000000e+01, 1.08000000e+02, 3.67000000e+00, 6.80000000e+00,\n",
              "        1.28262393e+03],\n",
              "       [1.06000000e+01, 8.80000000e+01, 5.70000000e-01, 1.95000000e+00,\n",
              "        5.19684807e+02],\n",
              "       [1.60000000e+01, 1.01000000e+02, 1.09000000e+00, 3.27000000e+00,\n",
              "        6.79614958e+02],\n",
              "       [1.68000000e+01, 1.00000000e+02, 1.41000000e+00, 5.75000000e+00,\n",
              "        4.49707983e+02],\n",
              "       [1.80000000e+01, 9.40000000e+01, 1.79000000e+00, 3.80000000e+00,\n",
              "        6.29639896e+02],\n",
              "       [1.90000000e+01, 8.70000000e+01, 3.10000000e+00, 4.45000000e+00,\n",
              "        4.19716904e+02],\n",
              "       [1.90000000e+01, 1.04000000e+02, 1.75000000e+00, 2.95000000e+00,\n",
              "        3.54734479e+02],\n",
              "       [1.81000000e+01, 9.80000000e+01, 2.65000000e+00, 4.60000000e+00,\n",
              "        6.77616022e+02],\n",
              "       [1.50000000e+01, 7.80000000e+01, 3.18000000e+00, 5.30000000e+00,\n",
              "        5.01691111e+02],\n",
              "       [1.96000000e+01, 7.80000000e+01, 2.00000000e+00, 4.68000000e+00,\n",
              "        5.09688341e+02],\n",
              "       [1.70000000e+01, 1.10000000e+02, 1.30000000e+00, 3.17000000e+00,\n",
              "        7.49573620e+02],\n",
              "       [1.68000000e+01, 1.51000000e+02, 1.28000000e+00, 2.85000000e+00,\n",
              "        7.17593567e+02],\n",
              "       [2.04000000e+01, 1.03000000e+02, 1.02000000e+00, 3.05000000e+00,\n",
              "        8.69477444e+02],\n",
              "       [2.50000000e+01, 8.60000000e+01, 2.86000000e+00, 3.38000000e+00,\n",
              "        4.09719758e+02],\n",
              "       [2.40000000e+01, 8.70000000e+01, 1.84000000e+00, 3.74000000e+00,\n",
              "        4.71701075e+02],\n",
              "       [3.00000000e+01, 1.39000000e+02, 2.89000000e+00, 3.35000000e+00,\n",
              "        9.84333333e+02],\n",
              "       [2.10000000e+01, 1.01000000e+02, 2.14000000e+00, 3.21000000e+00,\n",
              "        8.85461240e+02],\n",
              "       [1.60000000e+01, 9.70000000e+01, 1.57000000e+00, 3.80000000e+00,\n",
              "        4.27714579e+02],\n",
              "       [1.60000000e+01, 8.60000000e+01, 2.03000000e+00, 4.60000000e+00,\n",
              "        3.91724752e+02],\n",
              "       [1.80000000e+01, 1.12000000e+02, 1.32000000e+00, 2.65000000e+00,\n",
              "        4.99691796e+02],\n",
              "       [1.48000000e+01, 1.36000000e+02, 1.85000000e+00, 3.40000000e+00,\n",
              "        7.49573620e+02],\n",
              "       [2.30000000e+01, 1.01000000e+02, 2.55000000e+00, 2.57000000e+00,\n",
              "        4.62703940e+02],\n",
              "       [1.90000000e+01, 8.60000000e+01, 2.26000000e+00, 2.50000000e+00,\n",
              "        2.77752669e+02],\n",
              "       [1.88000000e+01, 8.60000000e+01, 2.53000000e+00, 3.90000000e+00,\n",
              "        7.13595930e+02],\n",
              "       [2.40000000e+01, 7.80000000e+01, 1.58000000e+00, 2.20000000e+00,\n",
              "        6.29639896e+02],\n",
              "       [2.25000000e+01, 8.50000000e+01, 1.59000000e+00, 4.80000000e+00,\n",
              "        5.14686584e+02],\n",
              "       [1.80000000e+01, 9.40000000e+01, 2.21000000e+00, 3.05000000e+00,\n",
              "        5.19684807e+02],\n",
              "       [1.80000000e+01, 9.90000000e+01, 1.94000000e+00, 2.62000000e+00,\n",
              "        4.49707983e+02],\n",
              "       [2.28000000e+01, 9.00000000e+01, 1.69000000e+00, 2.45000000e+00,\n",
              "        4.94693495e+02],\n",
              "       [2.60000000e+01, 8.80000000e+01, 1.61000000e+00, 2.60000000e+00,\n",
              "        5.61669048e+02],\n",
              "       [2.16000000e+01, 8.40000000e+01, 1.69000000e+00, 2.80000000e+00,\n",
              "        6.79614958e+02],\n",
              "       [2.36000000e+01, 7.00000000e+01, 1.59000000e+00, 1.74000000e+00,\n",
              "        6.24642214e+02],\n",
              "       [1.85000000e+01, 8.10000000e+01, 1.50000000e+00, 2.40000000e+00,\n",
              "        4.79698482e+02],\n",
              "       [2.20000000e+01, 8.60000000e+01, 1.25000000e+00, 3.60000000e+00,\n",
              "        4.49707983e+02],\n",
              "       [2.07000000e+01, 8.00000000e+01, 1.46000000e+00, 3.05000000e+00,\n",
              "        4.94693495e+02],\n",
              "       [1.80000000e+01, 8.80000000e+01, 2.25000000e+00, 2.15000000e+00,\n",
              "        2.89750000e+02],\n",
              "       [1.80000000e+01, 9.80000000e+01, 2.26000000e+00, 3.25000000e+00,\n",
              "        3.44736991e+02],\n",
              "       [1.90000000e+01, 1.62000000e+02, 2.27000000e+00, 2.60000000e+00,\n",
              "        9.36402151e+02],\n",
              "       [2.15000000e+01, 1.34000000e+02, 9.90000000e-01, 2.50000000e+00,\n",
              "        6.24642214e+02],\n",
              "       [1.60000000e+01, 8.50000000e+01, 2.50000000e+00, 2.90000000e+00,\n",
              "        4.27714579e+02],\n",
              "       [1.85000000e+01, 8.80000000e+01, 3.75000000e+00, 4.50000000e+00,\n",
              "        6.59625337e+02],\n",
              "       [1.80000000e+01, 8.80000000e+01, 2.99000000e+00, 2.30000000e+00,\n",
              "        4.05720884e+02],\n",
              "       [1.75000000e+01, 9.70000000e+01, 2.17000000e+00, 3.30000000e+00,\n",
              "        7.09598266e+02],\n",
              "       [1.85000000e+01, 8.80000000e+01, 1.36000000e+00, 2.45000000e+00,\n",
              "        5.61669048e+02],\n",
              "       [2.10000000e+01, 9.80000000e+01, 2.11000000e+00, 2.80000000e+00,\n",
              "        4.37711618e+02],\n",
              "       [1.95000000e+01, 8.60000000e+01, 1.64000000e+00, 2.06000000e+00,\n",
              "        4.14718338e+02],\n",
              "       [2.05000000e+01, 8.50000000e+01, 1.92000000e+00, 2.94000000e+00,\n",
              "        6.71619178e+02],\n",
              "       [2.20000000e+01, 9.00000000e+01, 1.84000000e+00, 2.70000000e+00,\n",
              "        3.14744250e+02],\n",
              "       [1.90000000e+01, 8.00000000e+01, 2.03000000e+00, 3.40000000e+00,\n",
              "        5.09688341e+02],\n",
              "       [2.25000000e+01, 8.40000000e+01, 1.76000000e+00, 3.30000000e+00,\n",
              "        4.87695842e+02],\n",
              "       [1.90000000e+01, 9.20000000e+01, 2.04000000e+00, 2.70000000e+00,\n",
              "        3.11744954e+02],\n",
              "       [2.00000000e+01, 9.40000000e+01, 2.92000000e+00, 2.65000000e+00,\n",
              "        6.79614958e+02],\n",
              "       [1.95000000e+01, 1.07000000e+02, 2.58000000e+00, 2.90000000e+00,\n",
              "        5.61669048e+02],\n",
              "       [2.10000000e+01, 8.80000000e+01, 2.27000000e+00, 2.00000000e+00,\n",
              "        3.24741876e+02],\n",
              "       [2.00000000e+01, 1.03000000e+02, 2.03000000e+00, 3.80000000e+00,\n",
              "        6.06650314e+02],\n",
              "       [2.10000000e+01, 8.80000000e+01, 2.01000000e+00, 3.08000000e+00,\n",
              "        4.33712810e+02],\n",
              "       [2.25000000e+01, 8.40000000e+01, 2.29000000e+00, 2.90000000e+00,\n",
              "        3.84726647e+02],\n",
              "       [2.15000000e+01, 8.50000000e+01, 2.17000000e+00, 1.90000000e+00,\n",
              "        4.06720603e+02],\n",
              "       [2.08000000e+01, 8.60000000e+01, 1.60000000e+00, 1.95000000e+00,\n",
              "        4.94693495e+02],\n",
              "       [2.25000000e+01, 1.08000000e+02, 2.09000000e+00, 2.06000000e+00,\n",
              "        3.44736991e+02],\n",
              "       [1.60000000e+01, 8.00000000e+01, 1.25000000e+00, 3.40000000e+00,\n",
              "        3.71730097e+02],\n",
              "       [1.90000000e+01, 8.70000000e+01, 1.64000000e+00, 1.28000000e+00,\n",
              "        5.63668258e+02],\n",
              "       [2.00000000e+01, 9.60000000e+01, 2.79000000e+00, 3.25000000e+00,\n",
              "        6.24642214e+02],\n",
              "       [2.85000000e+01, 1.19000000e+02, 5.08000000e+00, 6.00000000e+00,\n",
              "        4.64703308e+02],\n",
              "       [2.65000000e+01, 1.02000000e+02, 2.13000000e+00, 2.08000000e+00,\n",
              "        3.64731919e+02],\n",
              "       [2.15000000e+01, 8.60000000e+01, 2.65000000e+00, 2.60000000e+00,\n",
              "        3.79727984e+02],\n",
              "       [2.10000000e+01, 8.20000000e+01, 3.03000000e+00, 2.80000000e+00,\n",
              "        3.79727984e+02],\n",
              "       [2.10000000e+01, 8.50000000e+01, 2.65000000e+00, 2.76000000e+00,\n",
              "        3.77728516e+02],\n",
              "       [2.15000000e+01, 8.60000000e+01, 3.15000000e+00, 3.94000000e+00,\n",
              "        3.51735238e+02],\n",
              "       [2.85000000e+01, 9.20000000e+01, 2.24000000e+00, 3.00000000e+00,\n",
              "        4.65702991e+02],\n",
              "       [2.45000000e+01, 8.80000000e+01, 2.45000000e+00, 2.12000000e+00,\n",
              "        3.41737736e+02],\n",
              "       [2.20000000e+01, 8.00000000e+01, 1.75000000e+00, 2.60000000e+00,\n",
              "        5.79661800e+02],\n",
              "       [1.80000000e+01, 1.22000000e+02, 1.25000000e+00, 4.10000000e+00,\n",
              "        6.29639896e+02],\n",
              "       [2.00000000e+01, 1.04000000e+02, 1.22000000e+00, 5.40000000e+00,\n",
              "        5.29681193e+02],\n",
              "       [2.40000000e+01, 9.80000000e+01, 1.09000000e+00, 5.70000000e+00,\n",
              "        5.59669834e+02],\n",
              "       [2.15000000e+01, 1.06000000e+02, 1.20000000e+00, 5.00000000e+00,\n",
              "        5.99653367e+02],\n",
              "       [1.75000000e+01, 8.50000000e+01, 5.80000000e-01, 5.45000000e+00,\n",
              "        6.49630319e+02],\n",
              "       [1.85000000e+01, 9.40000000e+01, 6.60000000e-01, 7.10000000e+00,\n",
              "        6.94606789e+02],\n",
              "       [2.10000000e+01, 8.90000000e+01, 4.70000000e-01, 3.85000000e+00,\n",
              "        7.19592375e+02],\n",
              "       [2.50000000e+01, 9.60000000e+01, 6.00000000e-01, 5.00000000e+00,\n",
              "        5.14686584e+02],\n",
              "       [1.95000000e+01, 8.80000000e+01, 4.80000000e-01, 5.70000000e+00,\n",
              "        5.79661800e+02],\n",
              "       [2.40000000e+01, 1.01000000e+02, 6.00000000e-01, 4.92000000e+00,\n",
              "        5.89657635e+02],\n",
              "       [2.10000000e+01, 9.60000000e+01, 5.00000000e-01, 4.60000000e+00,\n",
              "        5.99653367e+02],\n",
              "       [2.00000000e+01, 8.90000000e+01, 5.00000000e-01, 5.60000000e+00,\n",
              "        7.79553055e+02],\n",
              "       [2.35000000e+01, 9.70000000e+01, 5.20000000e-01, 4.35000000e+00,\n",
              "        5.19684807e+02],\n",
              "       [2.00000000e+01, 9.20000000e+01, 8.00000000e-01, 4.40000000e+00,\n",
              "        5.49673709e+02],\n",
              "       [1.85000000e+01, 1.12000000e+02, 7.80000000e-01, 8.21000000e+00,\n",
              "        8.54491773e+02],\n",
              "       [2.10000000e+01, 1.02000000e+02, 5.50000000e-01, 4.00000000e+00,\n",
              "        8.29513986e+02],\n",
              "       [2.00000000e+01, 8.00000000e+01, 3.40000000e-01, 4.90000000e+00,\n",
              "        4.14718338e+02],\n",
              "       [2.15000000e+01, 8.60000000e+01, 6.50000000e-01, 7.65000000e+00,\n",
              "        6.24642214e+02],\n",
              "       [2.15000000e+01, 9.20000000e+01, 7.60000000e-01, 8.42000000e+00,\n",
              "        6.49630319e+02],\n",
              "       [2.15000000e+01, 1.13000000e+02, 1.39000000e+00, 9.40000000e+00,\n",
              "        5.49673709e+02],\n",
              "       [2.40000000e+01, 1.23000000e+02, 1.57000000e+00, 8.60000000e+00,\n",
              "        4.99691796e+02],\n",
              "       [2.20000000e+01, 1.12000000e+02, 1.36000000e+00, 1.08000000e+01,\n",
              "        4.79698482e+02],\n",
              "       [2.55000000e+01, 1.16000000e+02, 1.28000000e+00, 7.10000000e+00,\n",
              "        4.24715455e+02],\n",
              "       [1.85000000e+01, 9.80000000e+01, 8.30000000e-01, 1.05200000e+01,\n",
              "        6.74617607e+02],\n",
              "       [2.00000000e+01, 1.03000000e+02, 5.80000000e-01, 7.60000000e+00,\n",
              "        6.39635171e+02],\n",
              "       [2.20000000e+01, 9.30000000e+01, 6.30000000e-01, 7.90000000e+00,\n",
              "        7.24589365e+02],\n",
              "       [1.95000000e+01, 8.90000000e+01, 8.30000000e-01, 9.01000000e+00,\n",
              "        4.79698482e+02],\n",
              "       [2.70000000e+01, 9.70000000e+01, 5.80000000e-01, 7.50000000e+00,\n",
              "        8.79467433e+02],\n",
              "       [2.50000000e+01, 9.80000000e+01, 1.31000000e+00, 1.30000000e+01,\n",
              "        6.59625337e+02],\n",
              "       [2.25000000e+01, 8.90000000e+01, 1.10000000e+00, 1.17500000e+01,\n",
              "        6.19644501e+02],\n",
              "       [2.10000000e+01, 8.80000000e+01, 9.20000000e-01, 7.65000000e+00,\n",
              "        5.19684807e+02],\n",
              "       [2.00000000e+01, 1.07000000e+02, 5.60000000e-01, 5.88000000e+00,\n",
              "        6.79614958e+02],\n",
              "       [2.20000000e+01, 1.06000000e+02, 6.00000000e-01, 5.58000000e+00,\n",
              "        5.69665865e+02],\n",
              "       [1.85000000e+01, 1.06000000e+02, 7.00000000e-01, 5.28000000e+00,\n",
              "        6.74617607e+02],\n",
              "       [2.20000000e+01, 9.00000000e+01, 6.80000000e-01, 9.58000000e+00,\n",
              "        6.14646760e+02],\n",
              "       [2.25000000e+01, 8.80000000e+01, 4.70000000e-01, 6.62000000e+00,\n",
              "        5.19684807e+02],\n",
              "       [2.30000000e+01, 1.11000000e+02, 9.20000000e-01, 1.06800000e+01,\n",
              "        6.94606789e+02],\n",
              "       [1.95000000e+01, 8.80000000e+01, 6.60000000e-01, 1.02600000e+01,\n",
              "        6.84612273e+02],\n",
              "       [2.45000000e+01, 1.05000000e+02, 8.40000000e-01, 8.66000000e+00,\n",
              "        7.49573620e+02],\n",
              "       [2.50000000e+01, 1.12000000e+02, 9.60000000e-01, 8.50000000e+00,\n",
              "        6.29639896e+02],\n",
              "       [1.90000000e+01, 9.60000000e+01, 4.90000000e-01, 5.50000000e+00,\n",
              "        5.09688341e+02],\n",
              "       [1.95000000e+01, 8.60000000e+01, 5.10000000e-01, 9.89999900e+00,\n",
              "        4.69701717e+02],\n",
              "       [2.00000000e+01, 9.10000000e+01, 7.00000000e-01, 9.70000000e+00,\n",
              "        6.59625337e+02],\n",
              "       [2.05000000e+01, 9.50000000e+01, 6.10000000e-01, 7.70000000e+00,\n",
              "        7.39580060e+02],\n",
              "       [2.30000000e+01, 1.02000000e+02, 7.50000000e-01, 7.30000000e+00,\n",
              "        7.49573620e+02],\n",
              "       [2.00000000e+01, 1.20000000e+02, 6.90000000e-01, 1.02000000e+01,\n",
              "        8.34509700e+02],\n",
              "       [2.00000000e+01, 1.20000000e+02, 6.80000000e-01, 9.30000000e+00,\n",
              "        8.39505338e+02],\n",
              "       [2.45000000e+01, 9.60000000e+01, 7.60000000e-01, 9.20000000e+00,\n",
              "        5.59669834e+02]])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(ssb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Il6WFgGe-U",
        "outputId": "73c32a75-bb8a-40c5-ac22-21444a1b8d1a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score_func': <function sklearn.feature_selection._univariate_selection.chi2(X, y)>,\n",
              " 'k': 5,\n",
              " 'feature_names_in_': array(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "        'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "        'proanthocyanins', 'color_intensity', 'hue',\n",
              "        'od280/od315_of_diluted_wines', 'proline'], dtype=object),\n",
              " 'n_features_in_': 13,\n",
              " 'scores_': array([5.44549882e+00, 2.80686046e+01, 7.43380598e-01, 2.93836955e+01,\n",
              "        4.50263809e+01, 1.56230759e+01, 6.33343081e+01, 1.81548480e+00,\n",
              "        9.36828307e+00, 1.09016647e+02, 5.18253981e+00, 2.33898834e+01,\n",
              "        1.65189015e+04]),\n",
              " 'pvalues_': array([6.56938863e-02, 8.03489047e-07, 6.89567769e-01, 4.16304971e-07,\n",
              "        1.66972759e-10, 4.05034646e-04, 1.76656548e-14, 4.03433989e-01,\n",
              "        9.24066398e-03, 2.12488671e-24, 7.49248322e-02, 8.33587826e-06,\n",
              "        0.00000000e+00])}"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "T7zUXLvXGea5"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssb.scores_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eriIxsQSGjDS",
        "outputId": "57682c37-17c2-4585-a662-0d4d2ce54f02"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.44549882e+00, 2.80686046e+01, 7.43380598e-01, 2.93836955e+01,\n",
              "       4.50263809e+01, 1.56230759e+01, 6.33343081e+01, 1.81548480e+00,\n",
              "       9.36828307e+00, 1.09016647e+02, 5.18253981e+00, 2.33898834e+01,\n",
              "       1.65189015e+04])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(ssb.scores_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qLbcMufG1my",
        "outputId": "b7c32ab9-946a-4718-8325-6f21f327e130"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argsort(ssb.scores_)[-5:]    #=> 가장 큰것 5개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aMRQhcFG5aK",
        "outputId": "ec75ddce-10fa-4bf2-c9c0-a21541ba5cee"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  4,  6,  9, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.columns[np.argsort(ssb.scores_)[-5:]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WM0jKFkG-Hg",
        "outputId": "a4f15e23-4f98-4e17-bf3f-dc3cc9fd0f99"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['alcalinity_of_ash', 'magnesium', 'flavanoids', 'color_intensity',\n",
              "       'proline'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine3 = wine[wine.columns[np.argsort(ssb.scores_)[-5:]]]"
      ],
      "metadata": {
        "id": "P-pDKadDHHm4"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Uxdvpp0kItrK",
        "outputId": "c598033f-d0d7-4231-9818-53a3387324b2"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcalinity_of_ash  magnesium  flavanoids  color_intensity      proline\n",
              "0                 15.6      127.0        3.06             5.64  1064.175074\n",
              "1                 11.2      100.0        2.76             4.38  1049.210227\n",
              "2                 18.6      101.0        3.24             5.68  1183.718894\n",
              "3                 16.8      113.0        3.49             7.80  1483.564103\n",
              "4                 21.0      118.0        2.69             4.32   734.583208\n",
              "..                 ...        ...         ...              ...          ...\n",
              "173               20.5       95.0        0.61             7.70   739.580060\n",
              "174               23.0      102.0        0.75             7.30   749.573620\n",
              "175               20.0      120.0        0.69            10.20   834.509700\n",
              "176               20.0      120.0        0.68             9.30   839.505338\n",
              "177               24.5       96.0        0.76             9.20   559.669834\n",
              "\n",
              "[178 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2876bf91-3dce-453c-82d0-85fcd3cfacab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>3.06</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1064.175074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1049.210227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>3.24</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1183.718894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.49</td>\n",
              "      <td>7.80</td>\n",
              "      <td>1483.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.69</td>\n",
              "      <td>4.32</td>\n",
              "      <td>734.583208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.61</td>\n",
              "      <td>7.70</td>\n",
              "      <td>739.580060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>7.30</td>\n",
              "      <td>749.573620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.69</td>\n",
              "      <td>10.20</td>\n",
              "      <td>834.509700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.30</td>\n",
              "      <td>839.505338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.76</td>\n",
              "      <td>9.20</td>\n",
              "      <td>559.669834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2876bf91-3dce-453c-82d0-85fcd3cfacab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2876bf91-3dce-453c-82d0-85fcd3cfacab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2876bf91-3dce-453c-82d0-85fcd3cfacab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(DecisionTreeClassifier(), wine3.iloc[:,:-1], wine.target, cv=10).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IexXDHBUIwQi",
        "outputId": "5ae4aa92-de7c-4806-df00-8de6f70024f2"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9441176470588235"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "NzFQZIg3I4ur"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine3.iloc[:,:-1], wine.target, cv=10).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFKe79G0Jqol",
        "outputId": "da74281f-0614-46b5-bbc8-5b73d6f7bb20"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7761437908496731"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(KNeighborsClassifier(), wine.iloc[:,:-1], wine.target, cv=10).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCr3gF52JqhG",
        "outputId": "5c1143f2-6d54-455b-aa41-1acb092d145c"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6754901960784313"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wine3 wine 성능\n",
        "embedded 방식은 가지고 있는 알고리즘에 사용 cf.  filter방식 어떤 알고리즘에도 가능"
      ],
      "metadata": {
        "id": "I42uF2WP1wIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wapper 방식\n",
        "sequential feature\n",
        "Recursive feature"
      ],
      "metadata": {
        "id": "6XnXkE7JJrlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE, RFECV #=> crossvalidation 단점 모델이 크면클수록 시간이 많이 걸림"
      ],
      "metadata": {
        "id": "98JX4xpJKSTd"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "cTPmzWcTKYXd"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()"
      ],
      "metadata": {
        "id": "uXdbfrHUKeXQ"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(wine.iloc[:,:-1], wine.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "A2uWIY_kKirO",
        "outputId": "e5c62f7a-f64e-4c31-9840-bd35af6e99ef"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.decision_function(wine.iloc[:,:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kedezipoLPcU",
        "outputId": "0d9db2ba-f24d-4909-a2d1-95ca7ba47a68"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  4.56542056,  -1.94023644,  -2.62518412],\n",
              "       [  5.99752637,  -2.73788442,  -3.25964195],\n",
              "       [  5.39682621,  -3.72520612,  -1.67162009],\n",
              "       [  8.28118884,  -8.12098909,  -0.16019975],\n",
              "       [  0.27446598,   1.80652676,  -2.08099274],\n",
              "       [  8.11146907,  -7.31286026,  -0.79860881],\n",
              "       [  7.03779079,  -4.65384941,  -2.38394139],\n",
              "       [  5.5769768 ,  -3.90641329,  -1.67056352],\n",
              "       [  5.17397767,  -2.29898354,  -2.87499413],\n",
              "       [  4.89386402,  -4.2176635 ,  -0.67620052],\n",
              "       [  8.02599432,  -6.10137955,  -1.92461476],\n",
              "       [  5.84371824,  -4.08860299,  -1.75511525],\n",
              "       [  6.91388801,  -5.44734871,  -1.46653929],\n",
              "       [  7.41084475,  -3.61656215,  -3.7942826 ],\n",
              "       [ 10.34743746,  -9.43642731,  -0.91101015],\n",
              "       [  6.04993865,  -7.00630084,   0.9563622 ],\n",
              "       [  4.84183894,  -4.31488407,  -0.52695486],\n",
              "       [  3.80467446,  -3.49692644,  -0.30774802],\n",
              "       [  9.87224908, -11.10690317,   1.23465409],\n",
              "       [  3.27111465,  -1.43484737,  -1.83626728],\n",
              "       [  2.16397501,   0.50030786,  -2.66428288],\n",
              "       [  1.93736901,  -0.44641572,  -1.49095329],\n",
              "       [  4.56586472,  -0.0658466 ,  -4.50001812],\n",
              "       [  3.78411708,  -0.53289292,  -3.25122416],\n",
              "       [  1.98848722,   2.29411008,  -4.2825973 ],\n",
              "       [ -0.32929607,   3.3719304 ,  -3.04263433],\n",
              "       [  6.0325619 ,  -3.37801685,  -2.65454506],\n",
              "       [  5.77262989,  -3.40127252,  -2.37135737],\n",
              "       [  2.61201839,   0.68800287,  -3.30002126],\n",
              "       [  4.46443045,  -1.49922528,  -2.96520517],\n",
              "       [  4.69262439,  -3.05772847,  -1.63489593],\n",
              "       [  7.42679124,  -7.5565496 ,   0.12975836],\n",
              "       [  3.46541075,  -0.04449023,  -3.42092052],\n",
              "       [  4.12839204,  -2.88615958,  -1.24223246],\n",
              "       [  3.53497333,  -1.21622953,  -2.3187438 ],\n",
              "       [  2.44566909,  -0.06522087,  -2.38044822],\n",
              "       [  2.92109927,  -0.68241732,  -2.23868195],\n",
              "       [  4.03219023,  -2.02859222,  -2.00359801],\n",
              "       [  4.12983795,  -0.85573443,  -3.27410352],\n",
              "       [  3.20732121,  -1.16134666,  -2.04597455],\n",
              "       [  2.49531499,  -0.59746172,  -1.89785328],\n",
              "       [  4.15772369,  -2.57766633,  -1.58005735],\n",
              "       [  5.88152677,  -2.78467836,  -3.09684841],\n",
              "       [  1.44769804,   0.076846  ,  -1.52454404],\n",
              "       [  3.01893221,  -0.43471886,  -2.58421335],\n",
              "       [  4.18127524,  -3.56530495,  -0.61597029],\n",
              "       [  5.46278861,  -2.67914788,  -2.78364073],\n",
              "       [  4.46033753,  -2.3351921 ,  -2.12514544],\n",
              "       [  3.82945339,  -3.06857783,  -0.76087555],\n",
              "       [  6.07450049,  -7.89457091,   1.82007042],\n",
              "       [  6.9095409 ,  -6.50467961,  -0.40486129],\n",
              "       [  6.28007175,  -4.14963556,  -2.13043619],\n",
              "       [  6.76963339,  -5.42197183,  -1.34766156],\n",
              "       [  6.47093301,  -6.15740787,  -0.31352514],\n",
              "       [  4.09549581,  -2.92209994,  -1.17339587],\n",
              "       [  3.5008106 ,  -2.93305604,  -0.56775456],\n",
              "       [  3.6553962 ,  -2.33088684,  -1.32450936],\n",
              "       [  6.31850268,  -5.33110129,  -0.98740139],\n",
              "       [  6.50074475,  -5.43466176,  -1.06608299],\n",
              "       [  0.17807757,   2.83770752,  -3.0157851 ],\n",
              "       [ -0.09910208,   1.22518839,  -1.1260863 ],\n",
              "       [ -1.95567419,   0.20577922,   1.74989497],\n",
              "       [ -0.30615052,   2.51598484,  -2.20983432],\n",
              "       [ -0.93161225,   4.59767833,  -3.66606608],\n",
              "       [ -3.03983456,   5.47081406,  -2.4309795 ],\n",
              "       [  0.586404  ,   1.41264623,  -1.99905023],\n",
              "       [  1.1229873 ,   2.32388204,  -3.44686933],\n",
              "       [ -0.83543289,   2.67465201,  -1.83921912],\n",
              "       [  0.16812551,   1.90978749,  -2.07791299],\n",
              "       [ -0.68314962,   3.61295721,  -2.92980759],\n",
              "       [  0.0999056 ,   0.57100723,  -0.67091283],\n",
              "       [ -2.77890255,   7.54526182,  -4.76635927],\n",
              "       [ -2.91143099,   4.90542245,  -1.99399146],\n",
              "       [ -0.78425162,   4.53954797,  -3.75529635],\n",
              "       [  1.44133742,   2.32627889,  -3.76761631],\n",
              "       [ -1.5014668 ,   2.31900632,  -0.81753952],\n",
              "       [ -1.34046734,   3.23540751,  -1.89494017],\n",
              "       [ -1.64847634,   3.11064199,  -1.46216565],\n",
              "       [  0.58515837,   2.08691518,  -2.67207356],\n",
              "       [ -1.82597192,   5.54180636,  -3.71583444],\n",
              "       [ -2.702878  ,   7.66611843,  -4.96324043],\n",
              "       [  1.20415337,   1.86035884,  -3.06451221],\n",
              "       [ -1.57999546,   5.31277106,  -3.7327756 ],\n",
              "       [ -1.91389138,   0.63634817,   1.2775432 ],\n",
              "       [ -0.59225124,   4.73607767,  -4.14382643],\n",
              "       [ -1.51162137,   6.0061179 ,  -4.49449652],\n",
              "       [ -2.66805919,   5.58407742,  -2.91601823],\n",
              "       [ -2.67123989,   5.59908191,  -2.92784202],\n",
              "       [ -0.36077868,   2.766317  ,  -2.40553832],\n",
              "       [ -1.07792994,   5.81075399,  -4.73282405],\n",
              "       [ -1.34793492,   4.28661235,  -2.93867743],\n",
              "       [ -2.81148534,   4.07935103,  -1.26786568],\n",
              "       [ -2.06322188,   4.08507956,  -2.02185767],\n",
              "       [ -1.80459575,   6.662846  ,  -4.85825025],\n",
              "       [ -1.82224112,   5.12569658,  -3.30345547],\n",
              "       [  0.76811291,   3.19704038,  -3.96515329],\n",
              "       [ -2.56551619,   3.77749936,  -1.21198317],\n",
              "       [ -0.43775653,   4.97836015,  -4.54060363],\n",
              "       [  1.37210237,   2.69982766,  -4.07193003],\n",
              "       [ -0.46194396,   5.79339882,  -5.33145486],\n",
              "       [  1.01348905,   1.83920064,  -2.85268969],\n",
              "       [ -0.99777029,   4.27176941,  -3.27399912],\n",
              "       [ -1.8874054 ,   5.41454966,  -3.52714426],\n",
              "       [ -2.09020119,   5.88939592,  -3.79919473],\n",
              "       [  0.16534876,   3.62618523,  -3.791534  ],\n",
              "       [ -3.292651  ,   6.33141769,  -3.03876669],\n",
              "       [ -0.70793632,   3.62581537,  -2.91787905],\n",
              "       [ -2.43753595,   4.41242436,  -1.97488841],\n",
              "       [ -2.60393362,   6.94860995,  -4.34467633],\n",
              "       [  0.72475522,   4.5359285 ,  -5.26068372],\n",
              "       [ -0.10371773,   3.62018837,  -3.51647064],\n",
              "       [ -2.72280043,   7.16612584,  -4.44332541],\n",
              "       [ -0.75021939,   1.50536895,  -0.75514956],\n",
              "       [ -2.42272771,   5.43894965,  -3.01622194],\n",
              "       [ -2.62155888,   6.49801675,  -3.87645787],\n",
              "       [ -2.28491696,   7.19233608,  -4.90741912],\n",
              "       [ -1.69435554,   6.08550993,  -4.39115439],\n",
              "       [ -3.80944062,   8.15485253,  -4.34541192],\n",
              "       [ -1.35850479,   1.93408111,  -0.57557631],\n",
              "       [ -0.24986485,   4.57180951,  -4.32194466],\n",
              "       [  0.40080863,   3.25604137,  -3.65685001],\n",
              "       [ -2.70193091,   4.85177873,  -2.14984782],\n",
              "       [ -3.84964329,   6.74868354,  -2.89904025],\n",
              "       [ -1.25994276,   4.23282908,  -2.97288632],\n",
              "       [ -0.79824302,   5.16047238,  -4.36222936],\n",
              "       [ -1.89870955,   6.15551689,  -4.25680734],\n",
              "       [ -2.24272853,   5.7427863 ,  -3.50005776],\n",
              "       [ -4.04064318,   6.26369888,  -2.22305569],\n",
              "       [ -3.70462538,   8.39434321,  -4.68971783],\n",
              "       [ -0.69255781,   2.32367739,  -1.63111958],\n",
              "       [ -1.67500211,   1.17463578,   0.50036633],\n",
              "       [ -2.22058473,  -0.74734779,   2.96793252],\n",
              "       [ -3.26246381,  -0.21786753,   3.48033134],\n",
              "       [ -2.00626169,  -0.87607812,   2.88233981],\n",
              "       [ -0.52995944,  -1.426753  ,   1.95671244],\n",
              "       [ -0.45069356,  -4.55429341,   5.00498697],\n",
              "       [ -0.59945062,  -2.28978188,   2.88923251],\n",
              "       [ -3.09670091,  -1.04878574,   4.14548665],\n",
              "       [ -1.30658593,  -2.13208208,   3.43866801],\n",
              "       [ -2.68063898,   0.56318271,   2.11745626],\n",
              "       [ -1.76845149,   0.02415488,   1.74429661],\n",
              "       [  0.07651536,  -2.73454824,   2.65803288],\n",
              "       [ -3.19415414,   1.43712293,   1.7570312 ],\n",
              "       [ -1.17960519,  -0.61772318,   1.79732837],\n",
              "       [  0.87814044,  -8.03832877,   7.16018833],\n",
              "       [ -0.13930279,  -1.59027471,   1.7295775 ],\n",
              "       [ -2.62463613,  -1.22792625,   3.85256238],\n",
              "       [ -1.06312832,  -5.57989783,   6.64302615],\n",
              "       [ -1.28440272,  -5.34726312,   6.63166584],\n",
              "       [ -2.38144907,  -6.03400267,   8.41545174],\n",
              "       [ -3.85946875,  -3.04869618,   6.90816493],\n",
              "       [ -3.23702462,  -6.27154866,   9.50857328],\n",
              "       [ -4.932824  ,   0.68291672,   4.24990728],\n",
              "       [ -0.29845665,  -8.77050667,   9.06896332],\n",
              "       [ -1.86900234,  -3.35437637,   5.22337871],\n",
              "       [ -0.55459623,  -6.7493476 ,   7.30394383],\n",
              "       [ -1.74104455,  -5.53280324,   7.27384778],\n",
              "       [ -1.27544506,  -5.01334614,   6.2887912 ],\n",
              "       [ -1.98165114,  -7.82221672,   9.80386786],\n",
              "       [ -1.57544373,  -7.26128226,   8.83672599],\n",
              "       [ -1.81892434,  -4.16051937,   5.97944371],\n",
              "       [ -1.10433666,  -2.41616815,   3.52050481],\n",
              "       [ -2.44099462,  -0.87536674,   3.31636136],\n",
              "       [ -0.68364585,  -2.47710299,   3.16074884],\n",
              "       [ -1.9217438 ,  -6.10512084,   8.02686464],\n",
              "       [ -2.55149553,  -2.6605383 ,   5.21203384],\n",
              "       [ -1.67002677,  -8.18669877,   9.85672554],\n",
              "       [ -0.3685498 ,  -8.95482571,   9.32337551],\n",
              "       [ -1.77083609,  -4.91024349,   6.68107958],\n",
              "       [ -2.43741003,  -5.0023788 ,   7.43978883],\n",
              "       [ -2.09006096,  -1.54996038,   3.64002133],\n",
              "       [ -2.42503412,  -6.27565174,   8.70068586],\n",
              "       [ -0.93157003,  -6.61863838,   7.55020841],\n",
              "       [  0.08668759,  -7.14025823,   7.05357064],\n",
              "       [ -1.07943723,  -4.71684797,   5.79628521],\n",
              "       [  0.04618943,  -9.98506427,   9.93887484],\n",
              "       [ -0.25785854,  -7.58949509,   7.84735363],\n",
              "       [ -2.73515582,  -5.14471482,   7.87987064]])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfe = RFE(LogisticRegression(), n_features_to_select=5)"
      ],
      "metadata": {
        "id": "hOY-jTN7LW50"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfe.fit_transform(wine.iloc[:,:-1], wine.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQsuXwfRLfqF",
        "outputId": "b196a9b2-2d6b-4f67-dd7e-46ddcaf67a42"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.23    ,  2.43    ,  3.06    ,  5.64    ,  3.92    ],\n",
              "       [13.2     ,  2.14    ,  2.76    ,  4.38    ,  3.4     ],\n",
              "       [13.16    ,  2.67    ,  3.24    ,  5.68    ,  3.17    ],\n",
              "       [14.37    ,  2.5     ,  3.49    ,  7.8     ,  3.45    ],\n",
              "       [13.24    ,  2.87    ,  2.69    ,  4.32    ,  2.93    ],\n",
              "       [14.2     ,  2.45    ,  3.39    ,  6.75    ,  2.85    ],\n",
              "       [14.39    ,  2.45    ,  2.52    ,  5.25    ,  3.58    ],\n",
              "       [14.06    ,  2.61    ,  2.51    ,  5.05    ,  3.58    ],\n",
              "       [14.83    ,  2.17    ,  2.98    ,  5.2     ,  2.85    ],\n",
              "       [13.86    ,  2.27    ,  3.15    ,  7.22    ,  3.55    ],\n",
              "       [14.1     ,  2.3     ,  3.32    ,  5.75    ,  3.17    ],\n",
              "       [14.12    ,  2.32    ,  2.43    ,  5.      ,  2.82    ],\n",
              "       [13.75    ,  2.41    ,  2.76    ,  5.6     ,  2.9     ],\n",
              "       [14.75    ,  2.39    ,  3.69    ,  5.4     ,  2.73    ],\n",
              "       [14.38    ,  2.38    ,  3.64    ,  7.5     ,  3.      ],\n",
              "       [13.63    ,  2.7     ,  2.91    ,  7.3     ,  2.88    ],\n",
              "       [14.3     ,  2.72    ,  3.14    ,  6.2     ,  2.65    ],\n",
              "       [13.83    ,  2.62    ,  3.4     ,  6.6     ,  2.57    ],\n",
              "       [14.19    ,  2.48    ,  3.93    ,  8.7     ,  2.82    ],\n",
              "       [13.64    ,  2.56    ,  3.03    ,  5.1     ,  3.36    ],\n",
              "       [14.06    ,  2.28    ,  3.17    ,  5.65    ,  3.71    ],\n",
              "       [12.93    ,  2.65    ,  2.41    ,  4.5     ,  3.52    ],\n",
              "       [13.71    ,  2.36    ,  2.88    ,  3.8     ,  4.      ],\n",
              "       [12.85    ,  2.52    ,  2.37    ,  3.93    ,  3.63    ],\n",
              "       [13.5     ,  2.61    ,  2.61    ,  3.52    ,  3.82    ],\n",
              "       [13.05    ,  3.22    ,  2.68    ,  3.58    ,  3.2     ],\n",
              "       [13.39    ,  2.62    ,  2.94    ,  4.8     ,  3.22    ],\n",
              "       [13.3     ,  2.14    ,  2.19    ,  3.95    ,  2.77    ],\n",
              "       [13.87    ,  2.8     ,  2.97    ,  4.5     ,  3.4     ],\n",
              "       [14.02    ,  2.21    ,  2.33    ,  4.7     ,  3.59    ],\n",
              "       [13.73    ,  2.7     ,  3.25    ,  5.7     ,  2.71    ],\n",
              "       [13.58    ,  2.36    ,  3.19    ,  6.9     ,  2.88    ],\n",
              "       [13.68    ,  2.36    ,  2.69    ,  3.84    ,  2.87    ],\n",
              "       [13.76    ,  2.7     ,  2.74    ,  5.4     ,  3.      ],\n",
              "       [13.51    ,  2.65    ,  2.53    ,  4.2     ,  2.87    ],\n",
              "       [13.48    ,  2.41    ,  2.98    ,  5.1     ,  3.47    ],\n",
              "       [13.28    ,  2.84    ,  2.68    ,  4.6     ,  2.78    ],\n",
              "       [13.05    ,  2.55    ,  2.43    ,  4.25    ,  2.51    ],\n",
              "       [13.07    ,  2.1     ,  2.64    ,  3.7     ,  2.69    ],\n",
              "       [14.22    ,  2.51    ,  3.04    ,  5.1     ,  3.53    ],\n",
              "       [13.56    ,  2.31    ,  3.29    ,  6.13    ,  3.38    ],\n",
              "       [13.41    ,  2.12    ,  2.68    ,  4.28    ,  3.      ],\n",
              "       [13.88    ,  2.59    ,  3.56    ,  5.43    ,  3.56    ],\n",
              "       [13.24    ,  2.29    ,  2.63    ,  4.36    ,  3.      ],\n",
              "       [13.05    ,  2.1     ,  3.      ,  5.04    ,  3.35    ],\n",
              "       [14.21    ,  2.44    ,  2.65    ,  5.24    ,  3.33    ],\n",
              "       [14.38    ,  2.28    ,  3.17    ,  4.9     ,  3.44    ],\n",
              "       [13.9     ,  2.12    ,  3.39    ,  6.1     ,  3.33    ],\n",
              "       [14.1     ,  2.4     ,  2.92    ,  6.2     ,  2.75    ],\n",
              "       [13.94    ,  2.27    ,  3.54    ,  8.9     ,  3.1     ],\n",
              "       [13.05    ,  2.04    ,  3.27    ,  7.2     ,  2.91    ],\n",
              "       [13.83    ,  2.6     ,  2.99    ,  5.6     ,  3.37    ],\n",
              "       [13.82    ,  2.42    ,  3.74    ,  7.05    ,  3.26    ],\n",
              "       [13.77    ,  2.68    ,  2.79    ,  6.3     ,  2.93    ],\n",
              "       [13.74    ,  2.25    ,  2.9     ,  5.85    ,  3.2     ],\n",
              "       [13.56    ,  2.46    ,  2.78    ,  6.25    ,  3.03    ],\n",
              "       [14.22    ,  2.3     ,  3.      ,  6.38    ,  3.31    ],\n",
              "       [13.29    ,  2.68    ,  3.23    ,  6.      ,  2.84    ],\n",
              "       [13.72    ,  2.5     ,  3.67    ,  6.8     ,  2.87    ],\n",
              "       [12.37    ,  1.36    ,  0.57    ,  1.95    ,  1.82    ],\n",
              "       [12.33    ,  2.28    ,  1.09    ,  3.27    ,  1.67    ],\n",
              "       [12.64    ,  2.02    ,  1.41    ,  5.75    ,  1.59    ],\n",
              "       [13.67    ,  1.92    ,  1.79    ,  3.8     ,  2.46    ],\n",
              "       [12.37    ,  2.16    ,  3.1     ,  4.45    ,  2.87    ],\n",
              "       [12.17    ,  2.53    ,  1.75    ,  2.95    ,  2.23    ],\n",
              "       [12.37    ,  2.56    ,  2.65    ,  4.6     ,  2.3     ],\n",
              "       [13.11    ,  1.7     ,  3.18    ,  5.3     ,  3.18    ],\n",
              "       [12.37    ,  1.92    ,  2.      ,  4.68    ,  3.48    ],\n",
              "       [13.34    ,  2.36    ,  1.3     ,  3.17    ,  1.93    ],\n",
              "       [12.21    ,  1.75    ,  1.28    ,  2.85    ,  3.07    ],\n",
              "       [12.29    ,  2.21    ,  1.02    ,  3.05    ,  1.82    ],\n",
              "       [13.86    ,  2.67    ,  2.86    ,  3.38    ,  3.16    ],\n",
              "       [13.49    ,  2.24    ,  1.84    ,  3.74    ,  2.78    ],\n",
              "       [12.99    ,  2.6     ,  2.89    ,  3.35    ,  3.5     ],\n",
              "       [11.96    ,  2.3     ,  2.14    ,  3.21    ,  3.13    ],\n",
              "       [11.66    ,  1.92    ,  1.57    ,  3.8     ,  2.14    ],\n",
              "       [13.03    ,  1.71    ,  2.03    ,  4.6     ,  2.48    ],\n",
              "       [11.84    ,  2.23    ,  1.32    ,  2.65    ,  2.52    ],\n",
              "       [12.33    ,  1.95    ,  1.85    ,  3.4     ,  2.31    ],\n",
              "       [12.7     ,  2.4     ,  2.55    ,  2.57    ,  3.13    ],\n",
              "       [12.      ,  2.      ,  2.26    ,  2.5     ,  3.12    ],\n",
              "       [12.72    ,  2.2     ,  2.53    ,  3.9     ,  3.14    ],\n",
              "       [12.08    ,  2.51    ,  1.58    ,  2.2     ,  2.72    ],\n",
              "       [13.05    ,  2.32    ,  1.59    ,  4.8     ,  2.01    ],\n",
              "       [11.84    ,  2.58    ,  2.21    ,  3.05    ,  3.08    ],\n",
              "       [12.67    ,  2.24    ,  1.94    ,  2.62    ,  3.16    ],\n",
              "       [12.16    ,  2.31    ,  1.69    ,  2.45    ,  2.26    ],\n",
              "       [11.65    ,  2.62    ,  1.61    ,  2.6     ,  3.21    ],\n",
              "       [11.64    ,  2.46    ,  1.69    ,  2.8     ,  2.75    ],\n",
              "       [12.08    ,  2.3     ,  1.59    ,  1.74    ,  3.21    ],\n",
              "       [12.08    ,  2.32    ,  1.5     ,  2.4     ,  2.27    ],\n",
              "       [12.      ,  2.42    ,  1.25    ,  3.6     ,  2.65    ],\n",
              "       [12.69    ,  2.26    ,  1.46    ,  3.05    ,  2.06    ],\n",
              "       [12.29    ,  2.22    ,  2.25    ,  2.15    ,  3.3     ],\n",
              "       [11.62    ,  2.28    ,  2.26    ,  3.25    ,  2.96    ],\n",
              "       [12.47    ,  2.2     ,  2.27    ,  2.6     ,  2.63    ],\n",
              "       [11.81    ,  2.74    ,  0.99    ,  2.5     ,  2.26    ],\n",
              "       [12.29    ,  1.98    ,  2.5     ,  2.9     ,  2.74    ],\n",
              "       [12.37    ,  2.1     ,  3.75    ,  4.5     ,  2.77    ],\n",
              "       [12.29    ,  2.21    ,  2.99    ,  2.3     ,  2.83    ],\n",
              "       [12.08    ,  1.7     ,  2.17    ,  3.3     ,  2.96    ],\n",
              "       [12.6     ,  1.9     ,  1.36    ,  2.45    ,  2.77    ],\n",
              "       [12.34    ,  2.46    ,  2.11    ,  2.8     ,  3.38    ],\n",
              "       [11.82    ,  1.88    ,  1.64    ,  2.06    ,  2.44    ],\n",
              "       [12.51    ,  1.98    ,  1.92    ,  2.94    ,  3.57    ],\n",
              "       [12.42    ,  2.27    ,  1.84    ,  2.7     ,  3.3     ],\n",
              "       [12.25    ,  2.12    ,  2.03    ,  3.4     ,  3.17    ],\n",
              "       [12.72    ,  2.28    ,  1.76    ,  3.3     ,  2.42    ],\n",
              "       [12.22    ,  1.94    ,  2.04    ,  2.7     ,  3.02    ],\n",
              "       [11.61    ,  2.7     ,  2.92    ,  2.65    ,  3.26    ],\n",
              "       [11.46    ,  1.82    ,  2.58    ,  2.9     ,  2.81    ],\n",
              "       [12.52    ,  2.17    ,  2.27    ,  2.      ,  2.78    ],\n",
              "       [11.76    ,  2.92    ,  2.03    ,  3.8     ,  2.5     ],\n",
              "       [11.41    ,  2.5     ,  2.01    ,  3.08    ,  2.31    ],\n",
              "       [12.08    ,  2.5     ,  2.29    ,  2.9     ,  3.19    ],\n",
              "       [11.03    ,  2.2     ,  2.17    ,  1.9     ,  2.87    ],\n",
              "       [11.82    ,  1.99    ,  1.6     ,  1.95    ,  3.33    ],\n",
              "       [12.42    ,  2.19    ,  2.09    ,  2.06    ,  2.96    ],\n",
              "       [12.77    ,  1.98    ,  1.25    ,  3.4     ,  2.12    ],\n",
              "       [12.      ,  2.      ,  1.64    ,  1.28    ,  3.05    ],\n",
              "       [11.45    ,  2.42    ,  2.79    ,  3.25    ,  3.39    ],\n",
              "       [11.56    ,  3.23    ,  5.08    ,  6.      ,  3.69    ],\n",
              "       [12.42    ,  2.73    ,  2.13    ,  2.08    ,  3.12    ],\n",
              "       [13.05    ,  2.13    ,  2.65    ,  2.6     ,  3.1     ],\n",
              "       [11.87    ,  2.39    ,  3.03    ,  2.8     ,  3.64    ],\n",
              "       [12.07    ,  2.17    ,  2.65    ,  2.76    ,  3.28    ],\n",
              "       [12.43    ,  2.29    ,  3.15    ,  3.94    ,  2.84    ],\n",
              "       [11.79    ,  2.78    ,  2.24    ,  3.      ,  2.44    ],\n",
              "       [12.37    ,  2.3     ,  2.45    ,  2.12    ,  2.78    ],\n",
              "       [12.04    ,  2.38    ,  1.75    ,  2.6     ,  2.57    ],\n",
              "       [12.86    ,  2.32    ,  1.25    ,  4.1     ,  1.29    ],\n",
              "       [12.88    ,  2.4     ,  1.22    ,  5.4     ,  1.42    ],\n",
              "       [12.81    ,  2.4     ,  1.09    ,  5.7     ,  1.36    ],\n",
              "       [12.7     ,  2.36    ,  1.2     ,  5.      ,  1.29    ],\n",
              "       [12.51    ,  2.25    ,  0.58    ,  5.45    ,  1.51    ],\n",
              "       [12.6     ,  2.2     ,  0.66    ,  7.1     ,  1.58    ],\n",
              "       [12.25    ,  2.54    ,  0.47    ,  3.85    ,  1.27    ],\n",
              "       [12.53    ,  2.64    ,  0.6     ,  5.      ,  1.69    ],\n",
              "       [13.49    ,  2.19    ,  0.48    ,  5.7     ,  1.82    ],\n",
              "       [12.84    ,  2.61    ,  0.6     ,  4.92    ,  2.15    ],\n",
              "       [12.93    ,  2.7     ,  0.5     ,  4.6     ,  2.31    ],\n",
              "       [13.36    ,  2.35    ,  0.5     ,  5.6     ,  2.47    ],\n",
              "       [13.52    ,  2.72    ,  0.52    ,  4.35    ,  2.06    ],\n",
              "       [13.62    ,  2.35    ,  0.8     ,  4.4     ,  2.05    ],\n",
              "       [12.25    ,  2.2     ,  0.78    ,  8.21    ,  2.      ],\n",
              "       [13.16    ,  2.15    ,  0.55    ,  4.      ,  1.68    ],\n",
              "       [13.88    ,  2.23    ,  0.34    ,  4.9     ,  1.33    ],\n",
              "       [12.87    ,  2.48    ,  0.65    ,  7.65    ,  1.86    ],\n",
              "       [13.32    ,  2.38    ,  0.76    ,  8.42    ,  1.62    ],\n",
              "       [13.08    ,  2.36    ,  1.39    ,  9.4     ,  1.33    ],\n",
              "       [13.5     ,  2.62    ,  1.57    ,  8.6     ,  1.3     ],\n",
              "       [12.79    ,  2.48    ,  1.36    , 10.8     ,  1.47    ],\n",
              "       [13.11    ,  2.75    ,  1.28    ,  7.1     ,  1.33    ],\n",
              "       [13.23    ,  2.28    ,  0.83    , 10.52    ,  1.51    ],\n",
              "       [12.58    ,  2.1     ,  0.58    ,  7.6     ,  1.55    ],\n",
              "       [13.17    ,  2.32    ,  0.63    ,  7.9     ,  1.48    ],\n",
              "       [13.84    ,  2.38    ,  0.83    ,  9.01    ,  1.64    ],\n",
              "       [12.45    ,  2.64    ,  0.58    ,  7.5     ,  1.73    ],\n",
              "       [14.34    ,  2.7     ,  1.31    , 13.      ,  1.96    ],\n",
              "       [13.48    ,  2.64    ,  1.1     , 11.75    ,  1.78    ],\n",
              "       [12.36    ,  2.38    ,  0.92    ,  7.65    ,  1.58    ],\n",
              "       [13.69    ,  2.54    ,  0.56    ,  5.88    ,  1.82    ],\n",
              "       [12.85    ,  2.58    ,  0.6     ,  5.58    ,  2.11    ],\n",
              "       [12.96    ,  2.35    ,  0.7     ,  5.28    ,  1.75    ],\n",
              "       [13.78    ,  2.3     ,  0.68    ,  9.58    ,  1.68    ],\n",
              "       [13.73    ,  2.26    ,  0.47    ,  6.62    ,  1.75    ],\n",
              "       [13.45    ,  2.6     ,  0.92    , 10.68    ,  1.56    ],\n",
              "       [12.82    ,  2.3     ,  0.66    , 10.26    ,  1.75    ],\n",
              "       [13.58    ,  2.69    ,  0.84    ,  8.66    ,  1.8     ],\n",
              "       [13.4     ,  2.86    ,  0.96    ,  8.5     ,  1.92    ],\n",
              "       [12.2     ,  2.32    ,  0.49    ,  5.5     ,  1.83    ],\n",
              "       [12.77    ,  2.28    ,  0.51    ,  9.899999,  1.63    ],\n",
              "       [14.16    ,  2.48    ,  0.7     ,  9.7     ,  1.71    ],\n",
              "       [13.71    ,  2.45    ,  0.61    ,  7.7     ,  1.74    ],\n",
              "       [13.4     ,  2.48    ,  0.75    ,  7.3     ,  1.56    ],\n",
              "       [13.27    ,  2.26    ,  0.69    , 10.2     ,  1.56    ],\n",
              "       [13.17    ,  2.37    ,  0.68    ,  9.3     ,  1.62    ],\n",
              "       [14.13    ,  2.74    ,  0.76    ,  9.2     ,  1.6     ]])"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(rfe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z8R5i8vLqx-",
        "outputId": "0eb3a584-52e6-4653-eeae-5e06ee9d8c7a"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': LogisticRegression(),\n",
              " 'n_features_to_select': 5,\n",
              " 'step': 1,\n",
              " 'importance_getter': 'auto',\n",
              " 'verbose': 0,\n",
              " 'feature_names_in_': array(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "        'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "        'proanthocyanins', 'color_intensity', 'hue',\n",
              "        'od280/od315_of_diluted_wines', 'proline'], dtype=object),\n",
              " 'n_features_in_': 13,\n",
              " 'estimator_': LogisticRegression(),\n",
              " 'n_features_': 5,\n",
              " 'support_': array([ True, False,  True, False, False, False,  True, False, False,\n",
              "         True, False,  True, False]),\n",
              " 'ranking_': array([1, 4, 1, 5, 8, 7, 1, 3, 6, 1, 2, 1, 9])}"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfe2 = RFE(KNeighborsClassifier(), n_features_to_select=5)"
      ],
      "metadata": {
        "id": "pXBqBoX7Lv52"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfe2.fit_transform(wine.iloc[:,:-1], wine.target)  #=> error : 랩퍼 알고리즘 감싸서 순차적으로 없애거나 채움 c.f 임베디드 알고리즘 그 자제에서 중요성 나타남"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "ZIhSKek_L8nd",
        "outputId": "dbf05b59-1367-4527-8ea1-7bb44eb54a6f"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-4f5ab41077a4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#rfe2.fit_transform(wine.iloc[:,:-1], wine.target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             importances = _get_feature_importances(\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_importances_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0;34m\"when `importance_getter=='auto'`, the underlying \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0;34mf\"estimator {estimator.__class__.__name__} should have \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator KNeighborsClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector"
      ],
      "metadata": {
        "id": "oqfn0URZ6Hci"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs = SequentialFeatureSelector(LogisticRegression())"
      ],
      "metadata": {
        "id": "XKhuMxKR6fp6"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs.fit_transform(wine.iloc[:,:-1], wine.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqmp9hb56jUz",
        "outputId": "4aa27dc5-d009-4e2e-b04b-f442b7427a2e"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_sequential.py:211: FutureWarning: Leaving `n_features_to_select` to None is deprecated in 1.0 and will become 'auto' in 1.3. To keep the same behaviour as with None (i.e. select half of the features) and avoid this warning, you should manually set `n_features_to_select='auto'` and set tol=None when creating an instance.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.23,  2.43, 15.6 ,  3.06,  0.28,  1.04],\n",
              "       [13.2 ,  2.14, 11.2 ,  2.76,  0.26,  1.05],\n",
              "       [13.16,  2.67, 18.6 ,  3.24,  0.3 ,  1.03],\n",
              "       ...,\n",
              "       [13.27,  2.26, 20.  ,  0.69,  0.43,  0.59],\n",
              "       [13.17,  2.37, 20.  ,  0.68,  0.53,  0.6 ],\n",
              "       [14.13,  2.74, 24.5 ,  0.76,  0.56,  0.61]])"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(sfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sbqeLrA6poI",
        "outputId": "237c8e1f-61f1-437c-b590-3bb1f13e61f1"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': LogisticRegression(),\n",
              " 'n_features_to_select': 'warn',\n",
              " 'tol': None,\n",
              " 'direction': 'forward',\n",
              " 'scoring': None,\n",
              " 'cv': 5,\n",
              " 'n_jobs': None,\n",
              " 'feature_names_in_': array(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "        'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "        'proanthocyanins', 'color_intensity', 'hue',\n",
              "        'od280/od315_of_diluted_wines', 'proline'], dtype=object),\n",
              " 'n_features_in_': 13,\n",
              " 'n_features_to_select_': 6,\n",
              " 'support_': array([ True, False,  True,  True, False, False,  True,  True, False,\n",
              "        False,  True, False, False])}"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p(p-1)/2\n",
        "\n",
        "2p승\n",
        "\n",
        "4C2\n",
        "\n",
        "4*3/2 = 6\n",
        "\n",
        "subset selection\n",
        "\n",
        "\n",
        "forword 방식\n",
        "\n",
        "backword 방식 => 경우의 수가 적음\n",
        "\n",
        "지워감\n",
        "\n",
        "computational reasons\n",
        "\n",
        "stepwise => 단계적으로 wrapper방식\n",
        "\n",
        "결과가 다 다름, 비슷한 결과이지만 동일한 모델 아님\n",
        "\n",
        "섞어 가면서 하이브리드 방법으로\n",
        "\n",
        "scikit-feature\n",
        "\n",
        "40가지\n",
        "\n",
        "항상 잘 되는 알고리즘 없음 => 알고리즘 데이터에 따라\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CoAY1dla8fxH"
      }
    }
  ]
}