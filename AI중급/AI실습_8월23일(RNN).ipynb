{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1rg8EE4YeZn50052T+k9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukhyun-lee/stock_market_analysis/blob/main/AI%EC%A4%91%EA%B8%89/AI%EC%8B%A4%EC%8A%B5_8%EC%9B%9423%EC%9D%BC(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAAMNCyYK6EL",
        "outputId": "74db5ded-4454-4a04-8144-a17bdb2f01fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.15.2\n",
            "Uninstalling torchtext-0.15.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext-0.15.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchtext-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9rI88HGJb9h",
        "outputId": "a32a760d-c4d6-4e97-88e6-0b9633d8e0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAIpwxdZCzy-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "TEXT = Field(lower=True, fix_length=200, batch_first=False)  #[seq_len, batch_size, hidden_size] True이면 [batch_size, seq_len, hidden_size]\n",
        "LABEL = Field(sequential=False)"
      ],
      "metadata": {
        "id": "crthlDQRD0h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "train_data, test_data = IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4YxtbA0QoZ1",
        "outputId": "fdfbbdb7-4164-4d42-e459-a6c69010a378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 72.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data.examples[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc63ar_8UbXj",
        "outputId": "518fca2e-5d6f-4036-c6a4-747a63ca6f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['i',\n",
              "  'saw',\n",
              "  'this',\n",
              "  'on',\n",
              "  'tv',\n",
              "  'so',\n",
              "  'long',\n",
              "  'ago',\n",
              "  'that',\n",
              "  'i',\n",
              "  \"can't\",\n",
              "  'remember',\n",
              "  'when',\n",
              "  'it',\n",
              "  'was,',\n",
              "  'but',\n",
              "  'it',\n",
              "  'still',\n",
              "  'stands',\n",
              "  'out',\n",
              "  'as',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'scariest,',\n",
              "  'most',\n",
              "  'unnerving',\n",
              "  'films',\n",
              "  \"i've\",\n",
              "  'ever',\n",
              "  'seen.',\n",
              "  'there',\n",
              "  'is',\n",
              "  'a',\n",
              "  'simultaneously',\n",
              "  'subtle',\n",
              "  'but',\n",
              "  'intense',\n",
              "  'dread',\n",
              "  'induced',\n",
              "  'by',\n",
              "  'the',\n",
              "  'woman',\n",
              "  'in',\n",
              "  'black',\n",
              "  'lurking',\n",
              "  'at',\n",
              "  'the',\n",
              "  'edge',\n",
              "  'of',\n",
              "  'the',\n",
              "  'frame,',\n",
              "  'not',\n",
              "  'quite',\n",
              "  'clearly',\n",
              "  'visible,',\n",
              "  'so',\n",
              "  'that',\n",
              "  'you',\n",
              "  'feel',\n",
              "  '(like',\n",
              "  'the',\n",
              "  'solicitor',\n",
              "  'hero),',\n",
              "  'unsure',\n",
              "  'whether',\n",
              "  'its',\n",
              "  'just',\n",
              "  'imagination',\n",
              "  'or',\n",
              "  'not.',\n",
              "  'it',\n",
              "  'is',\n",
              "  'also',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'few',\n",
              "  'films',\n",
              "  'which',\n",
              "  'has',\n",
              "  'really',\n",
              "  'made',\n",
              "  'me',\n",
              "  'fearful',\n",
              "  'to',\n",
              "  'keep',\n",
              "  'watching.',\n",
              "  '\"production',\n",
              "  'values\"',\n",
              "  'be',\n",
              "  'hanged,',\n",
              "  'good',\n",
              "  'films',\n",
              "  'are',\n",
              "  'about',\n",
              "  'a',\n",
              "  \"director's\",\n",
              "  'ability',\n",
              "  'to',\n",
              "  'create',\n",
              "  'atmosphere',\n",
              "  'using',\n",
              "  'film,',\n",
              "  'actors,',\n",
              "  'locations/sets,',\n",
              "  'music,',\n",
              "  'attention',\n",
              "  'to',\n",
              "  'detail,',\n",
              "  'and',\n",
              "  '...imagination.',\n",
              "  'a',\n",
              "  'real',\n",
              "  'gem.'],\n",
              " 'label': 'pos'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "for example in train_data.examples:\n",
        "    text = [x.lower() for x in vars(example)['text']]\n",
        "    text = [x.replace(\"<br\",\"\") for x in text]\n",
        "    text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "    text = [s for s in text if s]\n",
        "    vars(example)['text'] = text"
      ],
      "metadata": {
        "id": "pVuunjNCXHr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(0), split_ratio=0.8)"
      ],
      "metadata": {
        "id": "QHm8lhNVX-IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEkwm03pYlF3",
        "outputId": "7e091167-02de-4a37-f2b8-868cf0058a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "metadata": {
        "id": "q0veBxYrZiQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErYiHHdCaDFp",
        "outputId": "cf3bcdbe-9a92-4d09-b506-35441963da74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 10002\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQV0GeBsaU-_",
        "outputId": "0e11cdbd-53b7-4c0d-d15a-f8da396ec4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7a8b27d120b0>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embeding_dim = 100\n",
        "hidden_size = 300\n",
        "\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "metadata": {
        "id": "xsJGH0Uialko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size):\n",
        "        super(RNNCell_Encoder, self).__init__()\n",
        "        self.rnn = nn.RNNCell(input_dim, hidden_size)\n",
        "\n",
        "    def forward(self, inputs): #------ inputs는 입력 시퀀스로 (시퀀스 길이, 배치, 임베딩(seq,batch, embedding))의 형태를 갖습니다.\n",
        "        bz = inputs.shape[1] #------ 배치를 가져옵니다.\n",
        "        ht = torch.zeros((bz, hidden_size)).to(device)# ------ 배치와 은닉층 뉴런의 크기를 0으로 초기화\n",
        "        for word in inputs:\n",
        "            ht = self.rnn(word, ht) #------ ②\n",
        "        return ht"
      ],
      "metadata": {
        "id": "IvVtpgI6bl1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.em = nn.Embedding(len(TEXT.vocab.stoi), embeding_dim) #------ ③\n",
        "        self.rnn = RNNCell_Encoder(embeding_dim, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.em(x)\n",
        "        x = self.rnn(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "azlFTaoG1RES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()   #다중분류\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "JkYyrSOH3X3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 학습을 위한 함수 공식\n",
        "##1.데이터로더에서 데이터를 가져와서 모델에 적용한 후 손실 함수를 적용하여 오차를 구함\n",
        "##2.옵티마이저를 이용하여 파라미터(가중치, 바이어스 등)를 업데이트"
      ],
      "metadata": {
        "id": "heUhQT_943JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(epoch, model, trainloader, validloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    model.train()  #dropout 켜짐\n",
        "    for b in trainloader:\n",
        "        x, y = b.text, b.label\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += (y_pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    valid_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in validloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            valid_correct += (y_pred == y).sum().item()\n",
        "            valid_total += y.size(0)\n",
        "            valid_running_loss += loss.item()\n",
        "\n",
        "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    epoch_valid_acc = valid_correct / valid_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'loss： ', round(epoch_loss, 3),\n",
        "          'accuracy:', round(epoch_acc, 3),\n",
        "          'valid_loss： ', round(epoch_valid_loss, 3),\n",
        "          'valid_accuracy:', round(epoch_valid_acc, 3)\n",
        "          )\n",
        "    return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc"
      ],
      "metadata": {
        "id": "U8iY2olf3siS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch,model,train_iterator,valid_iterator)\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    valid_acc.append(epoch_valid_acc)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw_FSIuF-rw8",
        "outputId": "449996ee-a106-44fa-d0f8-7745cb07df8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss：  0.011 accuracy: 0.528 valid_loss：  0.011 valid_accuracy: 0.509\n",
            "epoch:  1 loss：  0.011 accuracy: 0.534 valid_loss：  0.011 valid_accuracy: 0.51\n",
            "epoch:  2 loss：  0.011 accuracy: 0.536 valid_loss：  0.011 valid_accuracy: 0.503\n",
            "epoch:  3 loss：  0.011 accuracy: 0.545 valid_loss：  0.011 valid_accuracy: 0.511\n",
            "epoch:  4 loss：  0.011 accuracy: 0.55 valid_loss：  0.011 valid_accuracy: 0.513\n",
            "2676.221497774124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch,model,train_iterator,valid_iterator)\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    valid_acc.append(epoch_valid_acc)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxrRTwzcC7Bq",
        "outputId": "83f6ce50-719c-4798-91d1-60422fe0bffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss：  0.01 accuracy: 0.557 valid_loss：  0.011 valid_accuracy: 0.506\n",
            "epoch:  1 loss：  0.01 accuracy: 0.567 valid_loss：  0.011 valid_accuracy: 0.505\n",
            "epoch:  2 loss：  0.01 accuracy: 0.572 valid_loss：  0.011 valid_accuracy: 0.509\n",
            "epoch:  3 loss：  0.01 accuracy: 0.581 valid_loss：  0.011 valid_accuracy: 0.533\n",
            "epoch:  4 loss：  0.01 accuracy: 0.587 valid_loss：  0.011 valid_accuracy: 0.52\n",
            "epoch:  5 loss：  0.01 accuracy: 0.59 valid_loss：  0.011 valid_accuracy: 0.548\n",
            "epoch:  6 loss：  0.01 accuracy: 0.598 valid_loss：  0.012 valid_accuracy: 0.539\n",
            "epoch:  7 loss：  0.01 accuracy: 0.61 valid_loss：  0.012 valid_accuracy: 0.518\n",
            "epoch:  8 loss：  0.009 accuracy: 0.616 valid_loss：  0.012 valid_accuracy: 0.54\n",
            "epoch:  9 loss：  0.01 accuracy: 0.609 valid_loss：  0.012 valid_accuracy: 0.518\n",
            "epoch:  10 loss：  0.009 accuracy: 0.618 valid_loss：  0.012 valid_accuracy: 0.509\n",
            "epoch:  11 loss：  0.009 accuracy: 0.622 valid_loss：  0.012 valid_accuracy: 0.531\n",
            "epoch:  12 loss：  0.009 accuracy: 0.635 valid_loss：  0.013 valid_accuracy: 0.534\n",
            "epoch:  13 loss：  0.009 accuracy: 0.635 valid_loss：  0.013 valid_accuracy: 0.522\n",
            "epoch:  14 loss：  0.009 accuracy: 0.652 valid_loss：  0.013 valid_accuracy: 0.537\n",
            "epoch:  15 loss：  0.008 accuracy: 0.654 valid_loss：  0.014 valid_accuracy: 0.513\n",
            "epoch:  16 loss：  0.008 accuracy: 0.662 valid_loss：  0.014 valid_accuracy: 0.535\n",
            "epoch:  17 loss：  0.008 accuracy: 0.67 valid_loss：  0.014 valid_accuracy: 0.534\n",
            "epoch:  18 loss：  0.008 accuracy: 0.67 valid_loss：  0.015 valid_accuracy: 0.522\n",
            "epoch:  19 loss：  0.008 accuracy: 0.686 valid_loss：  0.016 valid_accuracy: 0.522\n",
            "4140.233971834183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(epoch, model, testloader):\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    test_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in testloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            test_correct += (y_pred == y).sum().item()\n",
        "            test_total += y.size(0)\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
        "    epoch_test_acc = test_correct / test_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'test_loss： ', round(epoch_test_loss, 3),\n",
        "          'test_accuracy:', round(epoch_test_acc, 3)\n",
        "          )\n",
        "    return epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "N-V14j8zFrF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_test_loss, epoch_test_acc = evaluate(epoch,\n",
        "                                               model,\n",
        "                                               test_iterator)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "    test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PytJmhqWGsCH",
        "outputId": "ca036352-74c0-46cc-b4c1-e2c9dff390b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  1 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  2 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  3 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  4 test_loss：  0.014 test_accuracy: 0.528\n",
            "4220.269709825516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_test_loss, epoch_test_acc = evaluate(epoch,\n",
        "                                               model,\n",
        "                                               test_iterator)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "    test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7rtGL-PIxJe",
        "outputId": "bfa936ea-2d3a-4a2c-ea35-b3477ded2040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  1 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  2 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  3 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  4 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  5 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  6 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  7 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  8 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  9 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  10 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  11 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  12 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  13 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  14 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  15 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  16 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  17 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  18 test_loss：  0.014 test_accuracy: 0.528\n",
            "epoch:  19 test_loss：  0.014 test_accuracy: 0.528\n",
            "4789.76269865036\n"
          ]
        }
      ]
    }
  ]
}