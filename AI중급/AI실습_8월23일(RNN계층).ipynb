{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBWQPB9BKpBlO1qKLLvSJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukhyun-lee/stock_market_analysis/blob/main/AI%EC%A4%91%EA%B8%89/AI%EC%8B%A4%EC%8A%B5_8%EC%9B%9423%EC%9D%BC(RNN%EA%B3%84%EC%B8%B5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXNKz_OOi4i",
        "outputId": "4fbdfb02-aa3e-4c34-a1cf-67f2c140f1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.15.2\n",
            "Uninstalling torchtext-0.15.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext-0.15.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchtext-0.15.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torchtext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrPDUTLeO69a",
        "outputId": "b3bb7af4-4be4-438e-c30d-25cf9c418586"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "MN0W8oByPAQz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "\n",
        "\n",
        "TEXT = Field(sequential = True, batch_first = True, lower = True)\n",
        "LABEL = Field(sequential = False, batch_first = True)\n",
        "\n",
        "from torchtext.datasets import IMDB\n",
        "train_data, test_data = IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(split_ratio = 0.8)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n"
      ],
      "metadata": {
        "id": "e5i4gg8WO-Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c0e0d7-24ed-4899-b1d8-20586d3db02a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 24.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2"
      ],
      "metadata": {
        "id": "PcD4kNaKPOqr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicRNN(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p = 0.2):\n",
        "        super(BasicRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        h_0 = self._init_state(batch_size = x.size(0))\n",
        "        x, _ = self.rnn(x, h_0)\n",
        "        h_t = x[:, -1, :]\n",
        "        self.dropout(h_t)\n",
        "        logit = torch.sigmoid(self.out(h_t))\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size = 1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
        "model = BasicRNN(n_layers = 1, hidden_dim = 256, n_vocab = vocab_size, embed_dim = 128, n_classes = n_classes, dropout_p = 0.5)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "Ke8FmVB0StsQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if b % 50 == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(e, b * len(x), len(train_iter.dataset), 100. * b / len(train_iter),loss.item()))"
      ],
      "metadata": {
        "id": "HxVBrOY-Sv4J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    model.eval()\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction = \"sum\")\n",
        "        total += y.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()   #view(y.size()) 확인 잘 해야\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "1kndfr-FUr5Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    train(model, optimizer, train_iterator)\n",
        "    val_loss, val_accuracy = evaluate(model, valid_iterator)\n",
        "    print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss, val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VmY1bgtVrC8",
        "outputId": "a8ee35de-ac63-4562-ed5a-6180739c49f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.697716\n",
            "Train Epoch: 1 [5000/20000 (25%)]\tLoss: 0.694374\n",
            "Train Epoch: 1 [10000/20000 (50%)]\tLoss: 0.699547\n",
            "Train Epoch: 1 [15000/20000 (75%)]\tLoss: 0.693828\n",
            "[EPOCH: 1], Validation Loss:  0.69 | Validation Accuracy:  0.51\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.691451\n",
            "Train Epoch: 2 [5000/20000 (25%)]\tLoss: 0.693829\n",
            "Train Epoch: 2 [10000/20000 (50%)]\tLoss: 0.693092\n",
            "Train Epoch: 2 [15000/20000 (75%)]\tLoss: 0.695535\n",
            "[EPOCH: 2], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.692204\n",
            "Train Epoch: 3 [5000/20000 (25%)]\tLoss: 0.693747\n",
            "Train Epoch: 3 [10000/20000 (50%)]\tLoss: 0.694691\n",
            "Train Epoch: 3 [15000/20000 (75%)]\tLoss: 0.690991\n",
            "[EPOCH: 3], Validation Loss:  0.69 | Validation Accuracy:  0.49\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.690755\n",
            "Train Epoch: 4 [5000/20000 (25%)]\tLoss: 0.693950\n",
            "Train Epoch: 4 [10000/20000 (50%)]\tLoss: 0.692472\n",
            "Train Epoch: 4 [15000/20000 (75%)]\tLoss: 0.692516\n",
            "[EPOCH: 4], Validation Loss:  0.69 | Validation Accuracy:  0.49\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.692667\n",
            "Train Epoch: 5 [5000/20000 (25%)]\tLoss: 0.692686\n",
            "Train Epoch: 5 [10000/20000 (50%)]\tLoss: 0.691631\n",
            "Train Epoch: 5 [15000/20000 (75%)]\tLoss: 0.690044\n",
            "[EPOCH: 5], Validation Loss:  0.69 | Validation Accuracy:  0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_iterator)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "id": "WzB2eQiYgwla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8a3c0a-1081-4244-c3fc-1b92d972c918"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.69 | Test Accuracy:  0.49\n"
          ]
        }
      ]
    }
  ]
}